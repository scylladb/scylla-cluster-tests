# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation; either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
#
# See LICENSE for more details.
#
# Copyright (c) 2016 ScyllaDB

# pylint: disable=too-many-lines

"""
Classes that introduce disruption in clusters.
"""

import inspect
import logging
import random
import time
import datetime
import threading
import os
import re
import traceback

from typing import List, Optional
from collections import OrderedDict, defaultdict

from invoke import UnexpectedExit
from cassandra import ConsistencyLevel  # pylint: disable=ungrouped-imports

from sdcm.cluster_aws import ScyllaAWSCluster
from sdcm.cluster import SCYLLA_YAML_PATH, NodeSetupTimeout, NodeSetupFailed, Setup
from sdcm.mgmt import TaskStatus
from sdcm.utils.common import remote_get_file, get_non_system_ks_cf_list, get_db_tables, generate_random_string, \
    update_certificates
from sdcm.utils.decorators import retrying
from sdcm.log import SDCMAdapter
from sdcm.keystore import KeyStore
from sdcm.prometheus import nemesis_metrics_obj
from sdcm import mgmt, wait
from sdcm.sct_events import DisruptionEvent, DbEventsFilter, Severity
from sdcm.db_stats import PrometheusDBStats
from sdcm.utils.alternator import ignore_alternator_client_errors
from test_lib.compaction import CompactionStrategy, get_compaction_strategy, get_compaction_random_additional_params
from test_lib.cql_types import CQLTypeBuilder


class NoFilesFoundToDestroy(Exception):
    pass


class NoKeyspaceFound(Exception):
    pass


class FilesNotCorrupted(Exception):
    pass


class LogContentNotFound(Exception):
    pass


class UnsupportedNemesis(Exception):
    """ raised from within a nemesis execution to skip this nemesis"""


class NoMandatoryParameter(Exception):
    """ raised from within a nemesis execution to skip this nemesis"""


class Nemesis:  # pylint: disable=too-many-instance-attributes,too-many-public-methods

    disruptive = False
    run_with_gemini = True
    networking = False
    MINUTE_IN_SEC = 60
    HOUR_IN_SEC = 60 * MINUTE_IN_SEC

    def __init__(self, tester_obj, termination_event):
        self.tester = tester_obj  # ClusterTester object
        self.cluster = tester_obj.db_cluster
        self.loaders = tester_obj.loaders
        self.monitoring_set = tester_obj.monitors
        self.target_node = None
        logger = logging.getLogger(__name__)
        self.log = SDCMAdapter(logger, extra={'prefix': str(self)})
        self.termination_event = termination_event
        self.operation_log = []
        self.current_disruption = None
        self.duration_list = []
        self.error_list = []
        self.interval = 60 * self.tester.params.get('nemesis_interval')  # convert from min to sec
        self.start_time = time.time()
        self.stats = {}
        self.metrics_srv = nemesis_metrics_obj()
        self.task_used_streaming = None
        self.filter_seed = self.cluster.params.get('nemesis_filter_seeds')
        self._random_sequence = None
        self._add_drop_column_max_per_drop = 5
        self._add_drop_column_max_per_add = 5
        self._add_drop_column_max_column_name_size = 10
        self._add_drop_column_max_columns = 200
        self._add_drop_column_columns_info = {}
        self._add_drop_column_target_table = []
        self._add_drop_column_tables_to_ignore = {
            'scylla_bench': '*',  # Ignore scylla-bench tables
            'alternator_usertable': '*',  # Ignore alternator tables
            'ks_truncate': 'counter1',  # Ignore counter table
            'keyspace1': 'counter1',  # Ignore counter table
            # TODO: issue https://github.com/scylladb/scylla/issues/6074. Waiting for dev conclusions
            'cqlstress_lwt_example': '*'  # Ignore LWT user-profile tables
        }

    def update_stats(self, disrupt, status=True, data=None):
        if not data:
            data = {}
        key = {True: 'runs', False: 'failures'}
        if disrupt not in self.stats:
            self.stats[disrupt] = {'runs': [], 'failures': [], 'cnt': 0}
        self.stats[disrupt][key[status]].append(data)
        self.stats[disrupt]['cnt'] += 1
        self.log.info('Update nemesis info: %s', self.stats)
        if self.tester.create_stats:
            self.tester.update({'nemesis': self.stats})

    def publish_event(self, disrupt, status=True, data=None):
        if not data:
            data = {}
        data['node'] = self.target_node
        DisruptionEvent(name=disrupt, status=status, **data)

    def set_current_running_nemesis(self, node):
        node.running_nemesis = self.__class__.__name__

    def set_target_node(self):
        """Set node to run nemesis on"""
        if self.filter_seed:
            non_seed_nodes = [node for node in self.cluster.nodes if not node.is_seed and not node.running_nemesis]
            # if non_seed_nodes is empty, nemesis would failed.
            self.log.debug("List of NonSeed nodes: {}".format([node.name for node in non_seed_nodes]))
            if not non_seed_nodes:
                self.log.warning("Cluster doesn't contain free nonseeds nodes. Test will failed")
            self.target_node = random.choice(non_seed_nodes)
        else:
            all_nodes = [node for node in self.cluster.nodes if not node.running_nemesis]
            self.target_node = random.choice(all_nodes)

        # Set name of nemesis, which is going to run on target node
        self.set_current_running_nemesis(node=self.target_node)

        self.log.info('Current Target: %s with running nemesis: %s', self.target_node, self.target_node.running_nemesis)

    def run(self, interval=None):
        if interval:
            self.interval = interval * 60
        self.log.info('Interval: %s s', self.interval)
        while not self.termination_event.isSet():
            cur_interval = self.interval
            self.set_target_node()
            self._set_current_disruption(report=False)
            try:
                self.disrupt()
            except UnsupportedNemesis:
                cur_interval = 0
            finally:
                self.target_node.running_nemesis = None
                self.termination_event.wait(timeout=cur_interval)

    def report(self):
        if self.duration_list:
            avg_duration = sum(self.duration_list) / len(self.duration_list)
        else:
            avg_duration = 0

        self.log.info('Report')
        self.log.info('DB Version: %s', getattr(self.cluster.nodes[0], "scylla_version", "n/a"))
        self.log.info('Interval: %s s', self.interval)
        self.log.info('Average duration: %s s', avg_duration)
        self.log.info('Total execution time: %s s', int(time.time() - self.start_time))
        self.log.info('Times executed: %s', len(self.duration_list))
        self.log.info('Unexpected errors: %s', len(self.error_list))
        self.log.info('Operation log:')
        for operation in self.operation_log:
            self.log.info(operation)

    def get_list_of_disrupt_methods_for_nemesis_subclasses(self, disruptive=None, run_with_gemini=None,
                                                           networking=None):  # pylint: disable=invalid-name
        if disruptive is not None:
            return self._get_subclasses_disrupt_methods(disruptive=disruptive)
        if run_with_gemini is not None:
            return self._get_subclasses_disrupt_methods(run_with_gemini=run_with_gemini)
        if networking is not None:
            return self._get_subclasses_disrupt_methods(networking=networking)
        return None

    def _get_subclasses_disrupt_methods(self, **kwargs):
        subclasses_list = self._get_subclasses(**kwargs)
        disrupt_methods_list = []
        for subclass in subclasses_list:
            method_name = re.search(
                r'self\.(?P<method_name>disrupt_[A-Za-z_]+?)\(.*\)', inspect.getsource(subclass), flags=re.MULTILINE)
            if method_name:
                disrupt_methods_list.append(method_name.group('method_name'))
        self.log.debug("Gathered subclass methods: {}".format(disrupt_methods_list))
        return disrupt_methods_list

    @staticmethod
    def _get_subclasses(**kwargs):
        filter_by_attribute, value = list(kwargs.items())[0]

        nemesis_subclasses = [nemesis for nemesis in Nemesis.__subclasses__()
                              if getattr(nemesis, filter_by_attribute) == value and
                              (nemesis not in COMPLEX_NEMESIS or nemesis not in DEPRECATED_LIST_OF_NEMESISES)]
        for inherit_nemesis_class in RELATIVE_NEMESIS_SUBCLASS_LIST:
            nemesis_subclasses.extend([nemesis for nemesis in inherit_nemesis_class.__subclasses__()
                                       if getattr(nemesis, filter_by_attribute) == value and
                                       (nemesis not in COMPLEX_NEMESIS or nemesis not in DEPRECATED_LIST_OF_NEMESISES)])
        return nemesis_subclasses

    def __str__(self):
        try:
            return str(self.__class__).split("'")[1]
        except Exception:  # pylint: disable=broad-except
            return str(self.__class__)

    def _kill_scylla_daemon(self):
        self.log.info('Kill all scylla processes in %s', self.target_node)
        kill_cmd = "sudo pkill -9 scylla"
        self.target_node.remoter.run(kill_cmd, ignore_status=True)

        # Let's wait for the target Node to have their services re-started
        self.log.info('Waiting scylla services to be restarted after we killed them...')
        self.target_node.wait_db_up(timeout=14400)
        self.log.info('Waiting JMX services to be restarted after we killed them...')
        self.target_node.wait_jmx_up()

    def disrupt_stop_wait_start_scylla_server(self, sleep_time=300):  # pylint: disable=invalid-name
        self._set_current_disruption('StopWaitStartService %s' % self.target_node)
        self.target_node.stop_scylla_server(verify_up=False, verify_down=True)
        self.log.info("Sleep for %s seconds", sleep_time)
        time.sleep(sleep_time)
        self.target_node.start_scylla_server(verify_up=True, verify_down=False)

    def disrupt_stop_start_scylla_server(self):  # pylint: disable=invalid-name
        self._set_current_disruption('StopStartService %s' % self.target_node)
        self.target_node.stop_scylla_server(verify_up=False, verify_down=True)
        self.target_node.start_scylla_server(verify_up=True, verify_down=False)

    # This nemesis should be run with "private" ip_ssh_connections till the issue #665 is not fixed
    def disrupt_restart_then_repair_node(self):  # pylint: disable=invalid-name
        self._set_current_disruption('RestartThenRepairNode %s' % self.target_node)
        self.target_node.restart()
        self.log.info('Waiting scylla services to start after node restart')
        self.target_node.wait_db_up(timeout=28800)  # 8 hours
        self.log.info('Waiting JMX services to start after node restart')
        self.target_node.wait_jmx_up()
        self.repair_nodetool_repair()

    def disrupt_hard_reboot_node(self):
        self._set_current_disruption('HardRebootNode %s' % self.target_node)
        self.target_node.reboot(hard=True)
        self.log.info('Waiting scylla services to start after node reboot')
        self.target_node.wait_db_up()
        self.log.info('Waiting JMX services to start after node reboot')
        self.target_node.wait_jmx_up()

    def disrupt_multiple_hard_reboot_node(self):  # pylint: disable=invalid-name
        num_of_reboots = random.randint(2, 10)
        for i in range(num_of_reboots):
            self._set_current_disruption('MultipleHardRebootNode %s' % self.target_node)
            self.log.debug("Rebooting {} out of {} times".format(i + 1, num_of_reboots))
            self.target_node.reboot(hard=True)
            if random.choice([True, False]):
                self.log.info('Waiting scylla services to start after node reboot')
                self.target_node.wait_db_up()
            else:
                self.log.info('Waiting JMX services to start after node reboot')
                self.target_node.wait_jmx_up()
            sleep_time = random.randint(0, 100)
            self.log.info(
                'Sleep {} seconds after hard reboot and service-up for node {}'.format(sleep_time, self.target_node))
            time.sleep(sleep_time)

    def disrupt_soft_reboot_node(self):
        self._set_current_disruption('SoftRebootNode %s' % self.target_node)
        self.target_node.reboot(hard=False)
        self.log.info('Waiting scylla services to start after node reboot')
        self.target_node.wait_db_up()
        self.log.info('Waiting JMX services to start after node reboot')
        self.target_node.wait_jmx_up()

    def disrupt_restart_with_resharding(self):
        self._set_current_disruption('RestartNodeWithResharding %s' % self.target_node)
        murmur3_partitioner_ignore_msb_bits = 15  # pylint: disable=invalid-name
        self.log.info(f'Restart node with resharding. New murmur3_partitioner_ignore_msb_bits value: '
                      f'{murmur3_partitioner_ignore_msb_bits}')
        self.target_node.restart_node_with_resharding(
            murmur3_partitioner_ignore_msb_bits=murmur3_partitioner_ignore_msb_bits)
        self.log.info('Waiting scylla services to start after node restart')
        self.target_node.wait_db_up()
        self.log.info('Waiting JMX services to start after node restart')
        self.target_node.wait_jmx_up()

        # Wait 5 minutes our before return back the default value
        self.log.debug(
            'Wait 5 minutes our before return murmur3_partitioner_ignore_msb_bits back the default value (12)')
        time.sleep(360)
        self.log.info('Set back murmur3_partitioner_ignore_msb_bits value to 12')
        self.target_node.restart_node_with_resharding()

    @retrying(n=10, allowed_exceptions=(NoKeyspaceFound, NoFilesFoundToDestroy))
    def _choose_file_for_destroy(self, ks_cfs):
        file_for_destroy = ''

        ks_cf_for_destroy = random.choice(ks_cfs)  # expected value as: 'keyspace1.standard1'

        ks_cf_for_destroy = ks_cf_for_destroy.replace('.', '/')
        files = self.target_node.remoter.run("sudo sh -c 'find /var/lib/scylla/data/%s-* -maxdepth 1 -type f'"
                                             % ks_cf_for_destroy, verbose=False)
        if files.stderr:
            raise NoFilesFoundToDestroy(
                'Failed to get data files for destroy in {}. Error: {}'.format(ks_cf_for_destroy,
                                                                               files.stderr))

        for one_file in files.stdout.split():
            if not one_file or '/' not in one_file:
                continue
            file_name = os.path.basename(one_file)
            # The file name like: /var/lib/scylla/data/scylla_bench/test-f60e4f30c98f11e98d46000000000002/mc-220-big-Data.db
            # For corruption we need to remove all files that their names are started from "mc-220-" (MC format)
            # Old format: "system-truncated-ka-" (system-truncated-ka-7-Data.db)
            # Search for "<digit>-" substring

            try:
                file_name_template = re.search(r"(.*-\d+)-", file_name).group(1)
            except Exception as error:  # pylint: disable=broad-except
                self.log.debug('File name "{file_name}" is not as expected for Scylla data files. '
                               'Search files for "{ks_cf_for_destroy}" table'.format(file_name=file_name,
                                                                                     ks_cf_for_destroy=ks_cf_for_destroy))
                self.log.debug('Error: {}'.format(error))
                continue

            file_for_destroy = one_file.replace(file_name, file_name_template + '-*')
            self.log.debug('Selected files for destroy: {}'.format(file_for_destroy))
            if file_for_destroy:
                break

        if not file_for_destroy:
            raise NoFilesFoundToDestroy('Data file for destroy is not found in {}'.format(ks_cf_for_destroy))

        return file_for_destroy

    def _destroy_data_and_restart_scylla(self):

        ks_cfs = get_non_system_ks_cf_list(db_node=self.target_node)
        if not ks_cfs:
            raise UnsupportedNemesis(
                'Non-system keyspace and table are not found. CorruptThenRepair nemesis can\'t be run')

        # Stop scylla service before deleting sstables to avoid partial deletion of files that are under compaction
        self.target_node.stop_scylla_server(verify_up=False, verify_down=True)

        try:
            # Remove 5 data files
            for _ in range(5):
                file_for_destroy = self._choose_file_for_destroy(ks_cfs)

                result = self.target_node.remoter.run('sudo rm -f %s' % file_for_destroy)
                if result.stderr:
                    raise FilesNotCorrupted('Files were not corrupted. CorruptThenRepair nemesis can\'t be run. '
                                            'Error: {}'.format(result))
                self.log.debug('Files {} were destroyed'.format(file_for_destroy))

        finally:
            self.target_node.start_scylla_server(verify_up=True, verify_down=False)

    def disrupt(self):
        raise NotImplementedError('Derived classes must implement disrupt()')

    def get_disrupt_name(self):
        return self.current_disruption.split()[0]

    def get_class_name(self):
        return self.__class__.__name__.replace('Monkey', '')

    def _set_current_disruption(self, label=None, report=True, node=None):
        current_node = node if node else self.target_node

        if not label:
            label = "%s on target node %s" % (self.__class__.__name__, current_node)
        self.log.debug('Set current_disruption -> %s', label)
        self.current_disruption = label
        self.log.info(label)
        if report:
            DisruptionEvent(type='start', name=self.get_disrupt_name(), status=True, node=str(current_node))

    def disrupt_destroy_data_then_repair(self):  # pylint: disable=invalid-name
        self._set_current_disruption('CorruptThenRepair %s' % self.target_node)
        self._destroy_data_and_restart_scylla()
        # try to save the node
        self.repair_nodetool_repair()

    def disrupt_destroy_data_then_rebuild(self):  # pylint: disable=invalid-name
        self._set_current_disruption('CorruptThenRebuild %s' % self.target_node)
        self._destroy_data_and_restart_scylla()
        # try to save the node
        self.repair_nodetool_rebuild()

    def disrupt_nodetool_drain(self):
        self._set_current_disruption('Drainer %s' % self.target_node)
        result = self.target_node.run_nodetool("drain", timeout=3600, coredump_on_timeout=True)
        self.target_node.run_nodetool("status", ignore_status=True, verbose=True)

        if result is not None:
            self.target_node.stop_scylla_server(verify_up=False, verify_down=True)
            self.target_node.start_scylla_server(verify_up=True, verify_down=False)

    @retrying(n=3, sleep_time=60, allowed_exceptions=(NodeSetupFailed, NodeSetupTimeout))
    def _add_and_init_new_cluster_node(self, old_node_ip=None, timeout=HOUR_IN_SEC * 6):
        """When old_node_private_ip is not None replacement node procedure is initiated"""
        self.log.info("Adding new node to cluster...")
        new_node = self.cluster.add_nodes(count=1, dc_idx=self.target_node.dc_idx, enable_auto_bootstrap=True)[0]
        self.monitoring_set.reconfigure_scylla_monitoring()
        self.set_current_running_nemesis(node=new_node)  # prevent to run nemesis on new node when running in parallel
        new_node.replacement_node_ip = old_node_ip
        try:
            self.cluster.wait_for_init(node_list=[new_node], timeout=timeout)
        except (NodeSetupFailed, NodeSetupTimeout):
            self.log.warning("Setup of the '%s' failed, removing it from list of nodes" % new_node)
            self.cluster.nodes.remove(new_node)
            self.log.warning("Node will not be terminated. Please terminate manually!!!")
            raise
        self.cluster.wait_for_nodes_up_and_normal(nodes=[new_node])
        return new_node

    def _terminate_cluster_node(self, node):
        self.cluster.terminate_node(node)
        self.monitoring_set.reconfigure_scylla_monitoring()

    def disrupt_nodetool_decommission(self, add_node=True):
        self._set_current_disruption('Decommission %s' % self.target_node)
        self.cluster.decommission(self.target_node)
        if add_node:
            # When adding node after decommission the node is declared as up only after it completed bootstrapping,
            # increasing the timeout for now
            new_node = self._add_and_init_new_cluster_node()
            # after decomission and add_node, the left nodes have data that isn't part of their tokens anymore.
            # In order to eliminate cases that we miss a "data loss" bug because of it, we cleanup this data.
            # This fix important when just user profile is run in the test and "keyspace1" doesn't exist.
            try:
                test_keyspaces = self.cluster.get_test_keyspaces()
                for node in self.cluster.nodes:
                    for keyspace in test_keyspaces:
                        node.run_nodetool(sub_cmd='cleanup', args=keyspace)
            finally:
                if new_node:
                    new_node.running_nemesis = None

    def disrupt_terminate_and_replace_node(self):  # pylint: disable=invalid-name
        # using "Replace a Dead Node" procedure from http://docs.scylladb.com/procedures/replace_dead_node/
        self._set_current_disruption('TerminateAndReplaceNode %s' % self.target_node)
        old_node_ip = self.target_node.ip_address
        self._terminate_cluster_node(self.target_node)
        new_node = self._add_and_init_new_cluster_node(old_node_ip)

        try:
            if new_node.get_scylla_config_param("enable_repair_based_node_ops") == 'false':
                self.repair_nodetool_repair(new_node)
        finally:
            new_node.running_nemesis = None

    def disrupt_no_corrupt_repair(self):
        self._set_current_disruption('NoCorruptRepair %s' % self.target_node)
        self.repair_nodetool_repair()

    def disrupt_major_compaction(self):
        self._set_current_disruption('MajorCompaction %s' % self.target_node)
        self.target_node.run_nodetool("compact")

    def disrupt_nodetool_refresh(self, big_sstable=True, skip_download=False):
        self._set_current_disruption('Refresh keyspace1.standard1 on {}'.format(self.target_node.name))
        if big_sstable:
            # 100G, the big file will be saved to GCE image
            # Fixme: It's very slow and unstable to download 100G files from S3 to GCE instances,
            #        currently we actually uploaded a small file (3.6 K) to S3.
            #        We had a solution to save the file in GCE image, it requires bigger boot disk.
            #        In my old test, the instance init is easy to fail. We can try to use a
            #        split shared disk to save the 100GB file.
            # 100M (500000 rows)
            sstable_url = 'https://s3.amazonaws.com/scylla-qa-team/refresh_nemesis/keyspace1.standard1.100M.tar.gz'
            sstable_file = '/tmp/keyspace1.standard1.100M.tar.gz'
            sstable_md5 = '9c5dd19cfc78052323995198b0817270'
        else:
            sstable_url = 'https://s3.amazonaws.com/scylla-qa-team/refresh_nemesis/keyspace1.standard1.tar.gz'
            sstable_file = "/tmp/keyspace1.standard1.tar.gz"
            sstable_md5 = 'c033a3649a1aec3ba9b81c446c6eecfd'
        if not skip_download:
            key_store = KeyStore()
            creds = key_store.get_scylladb_upload_credentials()
            remote_get_file(self.target_node.remoter, sstable_url, sstable_file,
                            hash_expected=sstable_md5, retries=2,
                            user_agent=creds['user_agent'])

        self.log.debug('Prepare keyspace1.standard1 if it does not exist')
        self._prepare_test_table(ks='keyspace1')
        result = self.target_node.run_nodetool(sub_cmd="cfstats", args="keyspace1.standard1")
        if result is not None and result.exit_status == 0:
            result = self.target_node.remoter.run("sudo ls -t /var/lib/scylla/data/keyspace1/")
            upload_dir = result.stdout.split()[0]
            self.target_node.remoter.run('sudo tar xvfz {} -C /var/lib/scylla/data/keyspace1/{}/upload/'.format(
                sstable_file, upload_dir))
            self.target_node.run_nodetool(sub_cmd="refresh", args="-- keyspace1 standard1")
            cmd = "select * from keyspace1.standard1 where key=0x32373131364f334f3830"
            result = self.target_node.run_cqlsh(cmd)
            assert '(1 rows)' in result.stdout, 'The key is not loaded by `nodetool refresh`'

    def disrupt_nodetool_enospc(self, sleep_time=30, all_nodes=False):
        if all_nodes:
            nodes = self.cluster.nodes
        else:
            nodes = [self.target_node]
        self._set_current_disruption('Enospc test on {}'.format([n.name for n in nodes]))

        def search_database_enospc(node):
            """
            Search system log by executing cmd inside node, use shell tool to
            avoid return and process huge data.
            """
            cmd = "sudo journalctl --no-tail --no-pager -u scylla-server.service|grep 'No space left on device'|wc -l"
            result = node.remoter.run(cmd, verbose=True)
            return int(result.stdout)

        def approach_enospc(node):
            # get the size of free space (default unit: KB)
            result = node.remoter.run("df -l|grep '/var/lib/scylla'")
            free_space_size = result.stdout.split()[3]

            occupy_space_size = int(int(free_space_size) * 90 / 100)
            occupy_space_cmd = 'sudo fallocate -l {}K /var/lib/scylla/occupy_90percent.{}'.format(
                occupy_space_size, datetime.datetime.now().strftime('%s'))
            self.log.debug('Cost 90% free space on /var/lib/scylla/ by {}'.format(occupy_space_cmd))
            try:
                node.remoter.run(occupy_space_cmd, verbose=True)
            except Exception as details:  # pylint: disable=broad-except
                self.log.error(str(details))
            return search_database_enospc(node) > orig_errors

        for node in nodes:
            with DbEventsFilter(type='NO_SPACE_ERROR', node=node), \
                    DbEventsFilter(type='BACKTRACE', line='No space left on device', node=node), \
                    DbEventsFilter(type='DATABASE_ERROR', line='No space left on device', node=node), \
                    DbEventsFilter(type='FILESYSTEM_ERROR', line='No space left on device', node=node):

                result = node.remoter.run('cat /proc/mounts')
                if '/var/lib/scylla' not in result.stdout:
                    self.log.error("Scylla doesn't use an individual storage, skip enospc test")
                    continue

                # check original ENOSPC error
                orig_errors = search_database_enospc(node)
                wait.wait_for(func=approach_enospc,
                              timeout=300,
                              step=5,
                              text='Wait for new ENOSPC error occurs in database',
                              node=node)

                self.log.debug('Sleep {} seconds before releasing space to scylla'.format(sleep_time))
                time.sleep(sleep_time)

                self.log.debug('Delete occupy_90percent file to release space to scylla-server')
                node.remoter.run('sudo rm -rf /var/lib/scylla/occupy_90percent.*')

                self.log.debug('Sleep a while before restart scylla-server')
                time.sleep(sleep_time / 2)
                node.remoter.run('sudo systemctl restart scylla-server.service')
                node.wait_db_up()

    def _deprecated_disrupt_stop_start(self):
        # TODO: We don't support fully stopping the AMI instance anymore
        # TODO: This nemesis has to be rewritten to just stop/start scylla server
        self.log.info('StopStart %s', self.target_node)
        self.target_node.restart()

    def call_random_disrupt_method(self, disrupt_methods=None, predefined_sequence=False):
        # pylint: disable=too-many-branches

        if not disrupt_methods:
            disrupt_methods = [attr[1] for attr in inspect.getmembers(self) if
                               attr[0].startswith('disrupt_') and
                               callable(attr[1])]
        else:
            disrupt_methods = [attr[1] for attr in inspect.getmembers(self) if
                               attr[0] in disrupt_methods and
                               callable(attr[1])]
        if not predefined_sequence:
            disrupt_method = random.choice(disrupt_methods)
        else:
            if not self._random_sequence:
                # Generate random sequence, every method has same chance to be called.
                # Here we use multiple original methods list, it will increase the chance
                # to call same method continuously.
                #
                # Adjust the rate according to the test duration. Try to call more unique
                # methods and don't wait to long time to meet the balance if the test
                # duration is short.
                test_duration = self.cluster.params.get('test_duration', default=180)
                if test_duration < 600:  # less than 10 hours
                    rate = 1
                elif test_duration < 4320:  # less than 3 days
                    rate = 2
                else:
                    rate = 3
                multiple_disrupt_methods = disrupt_methods * rate
                random.shuffle(multiple_disrupt_methods)
                self._random_sequence = multiple_disrupt_methods
            # consume the random sequence
            disrupt_method = self._random_sequence.pop()

        disrupt_method_name = disrupt_method.__name__.replace('disrupt_', '')
        self.log.info(">>>>>>>>>>>>>Started random_disrupt_method %s" % disrupt_method_name)
        self.metrics_srv.event_start(disrupt_method_name)
        try:
            disrupt_method()
        except Exception as exc:  # pylint: disable=broad-except
            error_msg = "Exception in random_disrupt_method %s: %s", disrupt_method_name, exc
            self.log.error(error_msg)
            self.error_list.append(error_msg)
            raise
        else:
            self.log.info("<<<<<<<<<<<<<Finished random_disrupt_method %s" % disrupt_method_name)
        finally:
            self.metrics_srv.event_stop(disrupt_method_name)

    def repair_nodetool_repair(self, node=None):
        node = node if node else self.target_node
        node.run_nodetool("repair")

    def repair_nodetool_rebuild(self):
        self.target_node.run_nodetool('rebuild')

    def disrupt_nodetool_cleanup(self):
        # This fix important when just user profile is run in the test and "keyspace1" doesn't exist.
        test_keyspaces = self.cluster.get_test_keyspaces()
        for node in self.cluster.nodes:
            self._set_current_disruption('NodetoolCleanupMonkey %s' % node, node=node)
            for keyspace in test_keyspaces:
                node.run_nodetool(sub_cmd="cleanup", args=keyspace)

    def _prepare_test_table(self, ks='keyspace1'):
        # get the count of the truncate table
        test_keyspaces = self.cluster.get_test_keyspaces()

        # if keyspace doesn't exist, create it by cassandra-stress
        if ks not in test_keyspaces:
            stress_cmd = "cassandra-stress write n=400000 cl=QUORUM -port jmx=6868 -mode native cql3 -schema 'replication(factor=3)' -log interval=5"
            cs_thread = self.tester.run_stress_thread(
                stress_cmd=stress_cmd, keyspace_name=ks, stop_test_on_failure=False)
            cs_thread.verify_results()

    def disrupt_truncate(self):
        self._set_current_disruption('TruncateMonkey {}'.format(self.target_node))

        keyspace_truncate = 'ks_truncate'
        table = 'standard1'

        self._prepare_test_table(ks=keyspace_truncate)

        # In order to workaround issue #4924 when truncate timeouts, we try to flush before truncate.
        self.target_node.run_nodetool("flush")
        # do the actual truncation
        self.target_node.run_cqlsh(cmd='TRUNCATE {}.{}'.format(keyspace_truncate, table), timeout=120)

    def _modify_table_property(self, name, val, filter_out_table_with_counter=False, modify_all_tables=False):
        disruption_name = "".join([p.strip().capitalize() for p in name.split("_")])
        self._set_current_disruption('ModifyTableProperties%s %s' % (disruption_name, self.target_node))

        ks_cfs = get_non_system_ks_cf_list(db_node=self.target_node,
                                           filter_out_table_with_counter=filter_out_table_with_counter,
                                           filter_out_mv=True)  # not allowed to modify MV

        keyspace_table = random.choice(ks_cfs) if ks_cfs else ks_cfs
        if not keyspace_table:
            raise UnsupportedNemesis(
                'Non-system keyspace and table are not found. ModifyTableProperties nemesis can\'t be run')

        cmd = "ALTER TABLE {keyspace_table} WITH {name} = {val};".format(
            keyspace_table=keyspace_table, name=name, val=val)
        self.log.info('_modify_table_property: {}'.format(cmd))
        with self.tester.cql_connection_patient(self.target_node) as session:
            session.execute(cmd)

    def _get_all_tables_with_no_compact_storage(self, tables_to_skip=None):
        """
        Return all tables with no "COMPACT STORAGE" in table code
        :param tables_to_skip: Dict of keyspaces/tables to be excluded from results.
            Examples:
                {'ks': 'table'} - will skip ks.table
                {'ks': '*'} - will skip any tables from keyspace "ks"
                {'*': 'table1,table2'} - will skip table1 and table2 from any keyspace
        :return: Dict of with keyspaces as key and list of table names as value
        """
        keyspaces = []
        output = {}
        if tables_to_skip is None:
            tables_to_skip = {}
        to_be_skipped_default = tables_to_skip.get('*', '').split(',')
        with self.tester.cql_connection_patient(self.tester.db_cluster.nodes[0]) as session:
            query_result = session.execute('SELECT keyspace_name FROM system_schema.keyspaces;')
            for result_rows in query_result:
                keyspaces.extend([row.lower() for row in result_rows if not row.lower().startswith("system")])
            for ks in keyspaces:
                to_be_skipped = tables_to_skip.get(ks, None)
                if to_be_skipped is None:
                    to_be_skipped = to_be_skipped_default
                elif to_be_skipped == '*':
                    continue
                elif to_be_skipped == '':
                    to_be_skipped = []
                else:
                    to_be_skipped = to_be_skipped.split(',') + to_be_skipped_default
                tables = get_db_tables(session, ks, with_compact_storage=False)
                if to_be_skipped:
                    tables = [table for table in tables if table not in to_be_skipped]
                if not tables:
                    continue
                output[ks] = tables
        return output

    def _add_drop_column_get_target_table(self, stored_target_table: list):
        current_tables = self._get_all_tables_with_no_compact_storage(self._add_drop_column_tables_to_ignore)
        if stored_target_table:
            if stored_target_table[1] in current_tables.get(stored_target_table[0], []):
                return stored_target_table
        if not current_tables:
            return None
        ks_name = next(iter(current_tables.keys()))
        table_name = current_tables[ks_name][0]
        return [ks_name, table_name]

    @staticmethod
    def _add_drop_column_get_added_columns_info(target_table: list, added_fields):
        ks = added_fields.get(target_table[0], None)
        if ks is None:
            output = {'column_names': {}, 'column_types': {}}
            added_fields[target_table[0]] = {target_table[1]: output}
            return output
        table = ks.get(target_table[1], None)
        if table is not None:
            return table
        ks[target_table[1]] = output = {'column_names': {}, 'column_types': {}}
        return output

    @staticmethod
    def _random_column_name(avoid_names=None, max_name_size=5):
        if avoid_names is None:
            avoid_names = []
        while True:
            column_name = generate_random_string(max_name_size)
            if column_name not in avoid_names:
                break
        return column_name

    def _add_drop_column_generate_columns_to_drop(self, added_columns_info):  # pylint: disable=too-many-branches
        drop = []
        for num in range(random.randrange(1, min(  # pylint: disable=unused-variable
                len(added_columns_info['column_names']) + 1, self._add_drop_column_max_per_drop + 1
        ))):
            choice = [n for n in added_columns_info['column_names'] if n not in drop]
            if choice:
                column_name = random.choice(choice)
                drop.append(column_name)
        return drop

    def _add_drop_column_run_cql_query(self, cmd, ks, consistency_level=ConsistencyLevel.ALL):  # pylint: disable=too-many-branches
        try:
            with self.tester.cql_connection_patient(self.target_node, keyspace=ks) as session:
                session.default_consistency_level = consistency_level
                session.execute(cmd)
        except Exception as exc:  # pylint: disable=broad-except
            self.log.debug(f"Add/Remove Column Nemesis: CQL query '{cmd}' execution has failed with error '{str(exc)}'")
            return False
        return True

    def _add_drop_column_generate_columns_to_add(self, added_columns_info):
        add = []
        #  pylint: disable=unused-variable
        upper_limit_columns_to_add = min(
            self._add_drop_column_max_columns - len(added_columns_info['column_names']),
            self._add_drop_column_max_per_add
        )
        for num in range(random.randrange(1, upper_limit_columns_to_add)):
            new_column_name = self._random_column_name(added_columns_info['column_names'].keys(),
                                                       self._add_drop_column_max_column_name_size)
            new_column_type = CQLTypeBuilder.get_random(added_columns_info['column_types'], allow_levels=10,
                                                        avoid_types=['counter'], forget_on_exhaust=True)
            if new_column_type is None:
                continue
            add.append([new_column_name, new_column_type])
        return add

    def _add_drop_column(self, drop=True, add=True):  # pylint: disable=too-many-branches
        self._add_drop_column_target_table = self._add_drop_column_get_target_table(
            self._add_drop_column_target_table)
        if self._add_drop_column_target_table is None:
            return
        added_columns_info = self._add_drop_column_get_added_columns_info(self._add_drop_column_target_table,
                                                                          self._add_drop_column_columns_info)
        added_columns_info.get('column_names', None)
        if not added_columns_info['column_names']:
            drop = False
        if drop:
            drop = self._add_drop_column_generate_columns_to_drop(added_columns_info)
        if add:
            add = self._add_drop_column_generate_columns_to_add(added_columns_info)
        if not add and not drop:
            return
        # TBD: Scylla does not support DROP and ADD in the same statement
        if drop:
            cmd = f"ALTER TABLE {self._add_drop_column_target_table[1]} DROP ( {', '.join(drop)} );"
            if self._add_drop_column_run_cql_query(cmd, self._add_drop_column_target_table[0]):
                for column_name in drop:
                    column_type = added_columns_info['column_names'][column_name]
                    del added_columns_info['column_names'][column_name]
        if add:
            cmd = f"ALTER TABLE {self._add_drop_column_target_table[1]} " \
                  f"ADD ( {', '.join(['%s %s' % (col[0], col[1]) for col in add])} );"
            if self._add_drop_column_run_cql_query(cmd, self._add_drop_column_target_table[0]):
                for column_name, column_type in add:
                    added_columns_info['column_names'][column_name] = column_type
                    column_type.remember_variant(added_columns_info['column_types'])

    def _add_drop_column_run_in_cycle(self):
        start_time = time.time()
        end_time = start_time + 600
        while time.time() < end_time:
            self._add_drop_column()

    def verify_initial_inputs_for_delete_nemesis(self):
        test_keyspaces = self.cluster.get_test_keyspaces()

        if 'scylla_bench' not in test_keyspaces:
            raise UnsupportedNemesis("This nemesis can run on scylla_bench test only")

        max_partitions_in_test_table = self.cluster.params.get('max_partitions_in_test_table')

        if not max_partitions_in_test_table:
            raise NoMandatoryParameter('This nemesis expects "max_partitions_in_test_table" to be set')

    def choose_partitions_for_delete(self, partitions_amount, ks_cf, with_clustering_key_data=False,
                                     exclude_partitions=None):
        """
        :type partitions_amount: int
        :type ks_cf: str
        :type with_clustering_key_data: bool
        :type exclude_partitions: list
        :return: defaultdict
        """
        if not exclude_partitions:
            exclude_partitions = []

        max_partitions_in_test_table = self.cluster.params.get('max_partitions_in_test_table')
        partition_range_with_data_validation = self.cluster.params.get('partition_range_with_data_validation')

        if partition_range_with_data_validation and '-' in partition_range_with_data_validation:
            partition_range_splitted = partition_range_with_data_validation.split('-')
            exclude_partitions.extend(
                [i for i in range(int(partition_range_splitted[0]), int(partition_range_splitted[1]))])  # pylint: disable=unnecessary-comprehension

        partitions_for_delete = defaultdict(list)
        with self.tester.cql_connection_patient(self.target_node, connect_timeout=300) as session:
            session.default_consistency_level = ConsistencyLevel.ONE

            for partition_key in [i*2+50 for i in range(max_partitions_in_test_table)]:
                if len(partitions_for_delete) == partitions_amount:
                    break

                if exclude_partitions and partition_key in exclude_partitions:
                    continue

                # The scylla_bench.test table is created WITH CLUSTERING ORDER BY (ck DESC).
                # So first returned value is max cl value in the partition
                cmd = f"select ck from {ks_cf} where pk={partition_key} limit 1"
                try:
                    result = session.execute(cmd, timeout=300)
                except Exception as exc:  # pylint: disable=broad-except
                    self.log.error(str(exc))
                    continue

                if not result:
                    continue

                if not with_clustering_key_data:
                    partitions_for_delete[partition_key] = []
                    continue

                # Suppose that min ck value is 0 in the partition
                partitions_for_delete[partition_key].extend([0, result[0].ck])

                if None in partitions_for_delete[partition_key]:
                    partitions_for_delete.pop(partition_key)

        self.log.debug(f'Partitions for delete: {partitions_for_delete}')
        return partitions_for_delete

    def run_deletions(self, queries, ks_cf):
        for cmd in queries:
            self.log.debug(f'delete query: {cmd}')
            with self.tester.cql_connection_patient(self.target_node, connect_timeout=300) as session:
                session.execute(cmd, timeout=3600)

        self.target_node.run_nodetool('flush', args=ks_cf.replace('.', ' '))

    def delete_half_partition(self, ks_cf):
        self.log.debug('Delete by range - half of partition')

        partitions_for_delete = self.choose_partitions_for_delete(10, ks_cf, with_clustering_key_data=True)
        if not partitions_for_delete:
            self.log.error('Not found partitions for delete')
            return partitions_for_delete

        queries = []
        for pkey, ckey in partitions_for_delete.items():
            queries.append(f"delete from {ks_cf} where pk = {pkey} and ck > {int(ckey[1]/2)}")
        self.run_deletions(queries=queries, ks_cf=ks_cf)

        return partitions_for_delete

    def delete_range_in_few_partitions(self, ks_cf, partitions_for_exclude_dict):
        self.log.debug('Delete same range in the few partitions')

        partitions_for_exclude = list(partitions_for_exclude_dict.keys())
        partitions_for_delete = self.choose_partitions_for_delete(10, ks_cf, with_clustering_key_data=True,
                                                                  exclude_partitions=partitions_for_exclude)
        if not partitions_for_delete:
            self.log.error('Not found partitions for delete')
            return []

        # Choose same "ck" values that exists for all partitions
        # min_clustering_key - the biggest from min(ck) value for all selected partitions
        # max_clustering_key - the smallest from max(ck) value for all selected partitions
        min_clustering_key = max([v[0] for v in partitions_for_delete.values()])
        max_clustering_key = min([v[1] for v in partitions_for_delete.values()])
        clustering_keys = []
        if max_clustering_key > min_clustering_key:
            third_ck = int((max_clustering_key - min_clustering_key) / 3)
            clustering_keys = range(min_clustering_key+third_ck, max_clustering_key-third_ck)

        if not clustering_keys:
            clustering_keys = range(min_clustering_key, max_clustering_key)

        queries = []
        for pkey in partitions_for_delete.keys():
            queries.append(f"delete from {ks_cf} where pk = {pkey} and ck >= {clustering_keys[0]} "
                           f"and ck <= {clustering_keys[-1]}")

        self.run_deletions(queries=queries, ks_cf=ks_cf)

        return list(partitions_for_delete.keys()) + partitions_for_exclude

    def disrupt_delete_10_full_partitions(self):
        """
        Delete few partitions in the table with large partitions
        """
        self.verify_initial_inputs_for_delete_nemesis()
        self._set_current_disruption('DeleteByPartitionsMonkey {}'.format(self.target_node))

        ks_cf = 'scylla_bench.test'
        partitions_for_delete = self.choose_partitions_for_delete(10, ks_cf)

        if not partitions_for_delete:
            self.log.error('Not found partitions for delete')
            return

        queries = []
        for partition_key in partitions_for_delete.keys():
            queries.append(f"delete from {ks_cf} where pk = {partition_key}")

        self.run_deletions(queries=queries, ks_cf=ks_cf)

    def disrupt_delete_by_rows_range(self):
        """
        Delete few partitions in the table with large partitions
        """
        self.verify_initial_inputs_for_delete_nemesis()
        self._set_current_disruption('DeleteByRowsRangeMonkey {}'.format(self.target_node))

        ks_cf = 'scylla_bench.test'
        partitions_for_exclude = self.delete_half_partition(ks_cf)

        self.delete_range_in_few_partitions(ks_cf, partitions_for_exclude)

    def disrupt_add_drop_column(self):
        """
        It searches for a table that allow add/drop columns (non compact storage table)
        If there is no such table it draw an error and quit
        It keeps tracking what columns where added and never drops column that were added by someone else.
        """
        self.log.debug("AddDropColumnMonkey: Started")
        self._add_drop_column_target_table = self._add_drop_column_get_target_table(
            self._add_drop_column_target_table)
        if self._add_drop_column_target_table is None:
            raise UnsupportedNemesis("AddDropColumnMonkey: can't find table to run on")
        self._add_drop_column_run_in_cycle()

    def modify_table_comment(self):
        # default: comment = ''
        prop_val = generate_random_string(24)
        self._modify_table_property(name="comment", val=f"'{prop_val}'")

    def modify_table_gc_grace_time(self):
        """
            The number of seconds after data is marked with a tombstone (deletion marker)
            before it is eligible for garbage-collection.
            default: gc_grace_seconds = 864000
        """
        self._modify_table_property(name="gc_grace_seconds", val=random.randint(216000, 864000))

    def modify_table_caching(self):
        """
           Caching optimizes the use of cache memory by a table without manual tuning.
           Cassandra weighs the cached data by size and access frequency.
           default: caching = {'keys': 'ALL', 'rows_per_partition': 'ALL'}
        """
        prop_val = dict(
            keys=random.choice(["NONE", "ALL"]),
            rows_per_partition=random.choice(["NONE", "ALL", random.randint(1, 10000)])
        )
        self._modify_table_property(name="caching", val=str(prop_val))

    def modify_table_bloom_filter_fp_chance(self):  # pylint: disable=invalid-name
        """
            The Bloom filter sets the false-positive probability for SSTable Bloom filters.
            When a client requests data, Cassandra uses the Bloom filter to check if the row
            exists before doing disk I/O. Bloom filter property value ranges from 0 to 1.0.
            Lower Bloom filter property probabilities result in larger Bloom filters that use more memory.
            The effects of the minimum and maximum values:
                0: Enables the unmodified, effectively the largest possible, Bloom filter.
                1.0: Disables the Bloom filter.
            default: bloom_filter_fp_chance = 0.01
        """
        self._modify_table_property(name="bloom_filter_fp_chance", val=random.random() / 2)

    def toggle_table_ics(self):
        """
            Alters a non-system table compaction strategy from ICS to any-other and vise versa.
        """
        list_additional_params = get_compaction_random_additional_params()
        all_ks_cfs = get_non_system_ks_cf_list(db_node=self.target_node)
        non_mview_ks_cfs = get_non_system_ks_cf_list(db_node=self.target_node, filter_out_mv=True)

        if not all_ks_cfs:
            raise UnsupportedNemesis(
                'Non-system keyspace and table are not found. toggle_tables_ics nemesis can\'t run')

        mview_ks_cfs = list(set(all_ks_cfs) - set(non_mview_ks_cfs))
        keyspace_table = random.choice(all_ks_cfs)
        keyspace, table = keyspace_table.split('.')
        cur_compaction_strategy = get_compaction_strategy(node=self.target_node, keyspace=keyspace,
                                                          table=table)
        if cur_compaction_strategy != CompactionStrategy.INCREMENTAL:
            new_compaction_strategy = CompactionStrategy.INCREMENTAL
        else:
            new_compaction_strategy = random.choice([strategy for strategy in list(
                CompactionStrategy) if strategy != CompactionStrategy.INCREMENTAL])
        new_compaction_strategy_as_dict = {'class': new_compaction_strategy.value}

        if new_compaction_strategy in [CompactionStrategy.INCREMENTAL, CompactionStrategy.SIZE_TIERED]:
            for param in list_additional_params:
                new_compaction_strategy_as_dict.update(param)
        alter_command_prefix = 'ALTER TABLE ' if keyspace_table not in mview_ks_cfs else 'ALTER MATERIALIZED VIEW '
        cmd = alter_command_prefix + \
            " {keyspace_table} WITH compaction = {new_compaction_strategy_as_dict};".format(**locals())
        self.log.debug("Toggle table ICS query to execute: {}".format(cmd))
        try:
            self.target_node.run_cqlsh(cmd)
        except UnexpectedExit as unexpected_exit:
            if "Unable to find compaction strategy" in str(unexpected_exit):
                raise UnsupportedNemesis("for this nemesis to work, you need ICS supported scylla version.")
            raise unexpected_exit

    def modify_table_compaction(self):
        """
            The compaction property defines the compaction strategy class for this table.
            default: compaction = {'class': 'SizeTieredCompactionStrategy'}
        """
        # TODO: Sub-properties for each of compaction strategies should also be tested
        strategies = ("SizeTieredCompactionStrategy", "DateTieredCompactionStrategy",
                      "TimeWindowCompactionStrategy", "LeveledCompactionStrategy")
        prop_val = {"class": random.choice(strategies)}
        self._modify_table_property(name="compaction", val=str(prop_val))

    def modify_table_compression(self):
        """
            The compression algorithm. Valid values are LZ4Compressor, SnappyCompressor, DeflateCompressor and
            ZstdCompressor
            default: compression = {}
        """
        algos = ("",  # no compression
                 "LZ4Compressor",
                 "SnappyCompressor",
                 "DeflateCompressor",
                 "ZstdCompressor")
        algo = random.choice(algos)
        prop_val = {"sstable_compression": algo}
        if algo:
            prop_val["chunk_length_kb"] = random.choice(["4K", "64KB", "1M"])
            prop_val["crc_check_chance"] = random.random()
        self._modify_table_property(name="compression", val=str(prop_val))

    def modify_table_crc_check_chance(self):
        """
            default: crc_check_chance = 1.0
        """
        self._modify_table_property(name="crc_check_chance", val=random.random())

    def modify_table_dclocal_read_repair_chance(self):  # pylint: disable=invalid-name
        """
            The probability that a successful read operation triggers a read repair.
            Unlike the repair controlled by read_repair_chance, this repair is limited to
            replicas in the same DC as the coordinator. The value must be between 0 and 1
            default: dclocal_read_repair_chance = 0.1
        """
        self._modify_table_property(name="dclocal_read_repair_chance", val=random.choice([0, 0.2, 0.5, 0.9]))

    def modify_table_default_time_to_live(self):  # pylint: disable=invalid-name
        """
            The value of this property is a number of seconds. If it is set, Cassandra applies a
            default TTL marker to each column in the table, set to this value. When the table TTL
            is exceeded, Cassandra tombstones the table.
            default: default_time_to_live = 0
        """
        # Select table without columns with "counter" type for this nemesis - issue #1037:
        #    Modify_table nemesis chooses first non-system table, and modify default_time_to_live of it.
        #    But table with counters doesn't support this
        self._modify_table_property(name="default_time_to_live", val=random.randint(864000, 630720000),
                                    filter_out_table_with_counter=True)  # max allowed TTL - 20 years (630720000)

    def modify_table_max_index_interval(self):
        """
            If the total memory usage of all index summaries reaches this value, Cassandra decreases
            the index summaries for the coldest SSTables to the maximum set by max_index_interval.
            The max_index_interval is the sparsest possible sampling in relation to memory pressure.
            default: max_index_interval = 2048
        """
        self._modify_table_property(name="max_index_interval", val=random.choice([1024, 4096, 8192]))

    def modify_table_min_index_interval(self):
        """
            The minimum gap between index entries in the index summary. A lower min_index_interval
            means the index summary contains more entries from the index, which allows Cassandra
            to search fewer index entries to execute a read. A larger index summary may also use
            more memory. The value for min_index_interval is the densest possible sampling of the index.
            default: min_index_interval = 128
        """
        self._modify_table_property(name="min_index_interval", val=random.choice([128, 256, 512]))

    def modify_table_memtable_flush_period_in_ms(self):  # pylint: disable=invalid-name
        """
            The number of milliseconds before Cassandra flushes memtables associated with this table.
            default: memtable_flush_period_in_ms = 0
        """
        self._modify_table_property(name="memtable_flush_period_in_ms", val=random.randint(1, 5000))

    def modify_table_read_repair_chance(self):
        """
            The probability that a successful read operation will trigger a read repair.of read repairs
            being invoked. Unlike the repair controlled by dc_local_read_repair_chance, this repair is
            not limited to replicas in the same DC as the coordinator. The value must be between 0 and 1
            default: read_repair_chance = 0.0
        """
        self._modify_table_property(name="read_repair_chance", val=random.choice([0, 0.2, 0.5, 0.9]))

    def modify_table_speculative_retry(self):
        """
            Use the speculative retry property to configure rapid read protection. In a normal read,
            Cassandra sends data requests to just enough replica nodes to satisfy the consistency
            level. In rapid read protection, Cassandra sends out extra read requests to other replicas,
            even after the consistency level has been met. The speculative retry property specifies
            the trigger for these extra read requests.
                ALWAYS: Send extra read requests to all other replicas after every read.
                Xpercentile: Cassandra constantly tracks each table's typical read latency (in milliseconds).
                             If you set speculative retry to Xpercentile, Cassandra sends redundant read
                             requests if the coordinator has not received a response after X percent of the
                             table's typical latency time.
                Nms: Send extra read requests to all other replicas if the coordinator node has not received
                     any responses within N milliseconds.
                NONE: Do not send extra read requests after any read.
            default: speculative_retry = '99.0PERCENTILE';
        """
        options = ("'ALWAYS'",
                   "'%spercentile'" % random.randint(1, 99),
                   "'%sms'" % random.randint(1, 1000))
        self._modify_table_property(name="speculative_retry", val=random.choice(options))

    def disrupt_toggle_table_ics(self):
        self._set_current_disruption('ToggleTableICS')
        self.toggle_table_ics()

    def disrupt_modify_table(self):
        # randomly select and run one of disrupt_modify_table* methods
        disrupt_func_name = random.choice([dm for dm in dir(self) if dm.startswith("modify_table")])
        disrupt_func = getattr(self, disrupt_func_name)
        disrupt_func()

    def disrupt_mgmt_backup(self):
        self._set_current_disruption('ManagementBackup')
        if not self.cluster.params.get('use_mgmt', default=None):
            raise UnsupportedNemesis('Scylla-manager configuration is not defined!')
        if not self.cluster.params.get('backup_bucket_location'):
            raise UnsupportedNemesis('backup bucket location configuration is not defined!')

        manager_node = self.monitoring_set.nodes[0]
        manager_tool = mgmt.get_scylla_manager_tool(manager_node=manager_node)
        self.log.debug("sctool version is : {}".format(manager_tool.version))

        cluster_name = self.cluster.name
        mgr_cluster = manager_tool.get_cluster(cluster_name)
        if not mgr_cluster:
            self.log.debug("Could not find cluster : {} on Manager. Adding it to Manager".format(cluster_name))
            targets = [[n, n.ip_address] for n in self.cluster.nodes]
            mgr_cluster = manager_tool.add_cluster(name=cluster_name, host=targets[0][1], disable_automatic_repair=True,
                                                   auth_token=self.monitoring_set.mgmt_auth_token)
        bucket_location_name = self.cluster.params.get('backup_bucket_location').split()
        mgr_task = mgr_cluster.create_backup_task(location_list=['s3:{}'.format(bucket_location_name[0])])

        succeeded, status = mgr_task.wait_for_task_done_status(timeout=54000)
        if succeeded and status == TaskStatus.DONE:
            self.log.info('Task: {} is done.'.format(mgr_task.id))
        if not succeeded:
            if status == TaskStatus.ERROR:
                assert succeeded, f'Backup task {mgr_task.id} failed'
            else:
                mgr_task.stop()
                assert succeeded, f'Backup task {mgr_task.id} timed out - while on status {status}'

    def disrupt_mgmt_repair_cli(self):
        self._set_current_disruption('ManagementRepair')
        if not self.cluster.params.get('use_mgmt', default=None):
            raise UnsupportedNemesis('Scylla-manager configuration is not defined!')

        manager_node = self.monitoring_set.nodes[0]
        manager_tool = mgmt.get_scylla_manager_tool(manager_node=manager_node)

        cluster_name = self.cluster.name
        mgr_cluster = manager_tool.get_cluster(cluster_name)
        if not mgr_cluster:
            self.log.debug("Could not find cluster : {} on Manager. Adding it to Manager".format(cluster_name))
            ip_addr_attr = 'public_ip_address' if self.cluster.params.get('cluster_backend') != 'gce' and \
                Setup.INTRA_NODE_COMM_PUBLIC else 'private_ip_address'
            targets = [getattr(n, ip_addr_attr) for n in self.cluster.nodes]
            mgr_cluster = manager_tool.add_cluster(name=cluster_name, host=targets[0], disable_automatic_repair=True,
                                                   auth_token=self.monitoring_set.mgmt_auth_token)
        mgr_task = mgr_cluster.create_repair_task()
        task_final_status = mgr_task.wait_and_get_final_status(timeout=86400)  # timeout is 24 hours
        assert task_final_status == TaskStatus.DONE, 'Task: {} final status is: {}.'.format(
            mgr_task.id, str(mgr_task.status))
        self.log.info('Task: {} is done.'.format(mgr_task.id))

        self.log.debug("sctool version is : {}".format(manager_tool.version))

    def disrupt_abort_repair(self):
        """
        Start repair target_node in background, then try to abort the repair streaming.
        """
        self._set_current_disruption('AbortRepairMonkey')
        self.log.debug("Start repair target_node in background")
        thread1 = threading.Thread(target=self.repair_nodetool_repair, name='NodeToolRepairThread')
        thread1.start()

        def repair_streaming_exists():
            active_repair_cmd = 'curl -s -X GET --header "Content-Type: application/json" --header ' \
                                '"Accept: application/json" "http://127.0.0.1:10000/storage_service/active_repair/"'
            result = self.target_node.remoter.run(active_repair_cmd)
            active_repairs = re.match(r".*\[(\d)+\].*", result.stdout)
            if active_repairs:
                self.log.debug("Found '%s' active repairs", active_repairs.group(1))
                return True
            return False

        wait.wait_for(func=repair_streaming_exists,
                      timeout=300,
                      step=1,
                      throw_exc=True,
                      text='Wait for repair starts')

        self.log.debug("Abort repair streaming by storage_service/force_terminate_repair API")
        with DbEventsFilter(type='DATABASE_ERROR', line="repair's stream failed: streaming::stream_exception",
                            node=self.target_node), \
                DbEventsFilter(type='RUNTIME_ERROR', line='Can not find stream_manager', node=self.target_node), \
                DbEventsFilter(type='RUNTIME_ERROR', line='is aborted', node=self.target_node), \
                DbEventsFilter(type='RUNTIME_ERROR', line='Failed to repair', node=self.target_node):
            self.target_node.remoter.run(
                'curl -X POST --header "Content-Type: application/json" --header "Accept: application/json" "http://127.0.0.1:10000/storage_service/force_terminate_repair"')
            thread1.join(timeout=120)
            time.sleep(10)  # to make sure all failed logs/events, are ignored correctly

        self.log.debug("Execute a complete repair for target node")
        self.repair_nodetool_repair()

    def disrupt_validate_hh_short_downtime(self):  # pylint: disable=invalid-name
        """
            Validates that hinted handoff mechanism works: there were no drops and errors
            during short stop of one of the nodes in cluster
        """
        self._set_current_disruption("ValidateHintedHandoffShortDowntime")
        if self.cluster.params.get('hinted_handoff', 'enabled') == 'disabled':
            raise UnsupportedNemesis('For this nemesis to work, `hinted_handoff` needs to be set to `enabled`')

        start_time = time.time()
        self.target_node.stop_scylla()
        time.sleep(10)
        self.target_node.start_scylla()

        # Wait until all other nodes see the target node as UN
        # Only then we can expect that hint sending started on all nodes
        def target_node_reported_un_by_others():
            for node in self.cluster.nodes:
                if node is not self.target_node:
                    self.cluster.check_nodes_up_and_normal(nodes=[self.target_node], verification_node=node)
            return True

        wait.wait_for(func=target_node_reported_un_by_others,
                      timeout=300,
                      step=5,
                      throw_exc=True,
                      text='Wait for target_node to be seen as UN by others')

        time.sleep(120)  # Wait to complete hints sending
        assert self.tester.hints_sending_in_progress() is False, "Hints are sent too slow"
        self.tester.verify_no_drops_and_errors(starting_from=start_time)

    def disrupt_snapshot_operations(self):
        self._set_current_disruption('SnapshotOperations')
        result = self.target_node.run_nodetool('snapshot')
        self.log.debug(result)
        snapshot_name = re.findall(r'(\d+)', result.stdout, re.MULTILINE)[0]
        result = self.target_node.run_nodetool('listsnapshots')
        self.log.debug(result)
        if snapshot_name in result.stdout:
            self.log.info('Snapshot %s created' % snapshot_name)
        else:
            raise Exception(f"Snapshot {snapshot_name} wasn't found in: \n{result.stdout}")

        result = self.target_node.run_nodetool('clearsnapshot')
        self.log.debug(result)

    def disrupt_show_toppartitions(self):
        def _parse_toppartitions_output(output):
            """parsing output of toppartitions

            input format stored in output parameter:
            WRITES Sampler:
              Cardinality: ~10 (15 capacity)
              Top 10 partitions:
                Partition     Count       +/-
                9        11         0
                0         1         0
                1         1         0

            READS Sampler:
              Cardinality: ~10 (256 capacity)
              Top 3 partitions:
                Partition     Count       +/-
                0         3         0
                1         3         0
                2         3         0
                3         2         0

            return Dict:
            {
                'READS': {
                    'toppartitions': '10',
                    'partitions': OrderedDict('0': {'count': '1', 'margin': '0'},
                                              '1': {'count': '1', 'margin': '0'},
                                              '2': {'count': '1', 'margin': '0'}),
                    'cardinality': '10',
                    'capacity': '256',
                },
                'WRITES': {
                    'toppartitions': '10',
                    'partitions': OrderedDict('10': {'count': '1', 'margin': '0'},
                                              '11': {'count': '1', 'margin': '0'},
                                              '21': {'count': '1', 'margin': '0'}),
                    'cardinality': '10',
                    'capacity': '256',
                    'sampler': 'WRITES'
                }
            }


            Arguments:
                output {str} -- stdout of nodetool topparitions command

            Returns:
                dict -- result of parsing
            """

            pattern1 = r"(?P<sampler>[A-Z]+)\sSampler:\W+Cardinality:\s~(?P<cardinality>[0-9]+)\s\((?P<capacity>[0-9]+)\scapacity\)\W+Top\s(?P<toppartitions>[0-9]+)\spartitions:"
            pattern2 = r"(?P<partition>[\w:]+)\s+(?P<count>[\d]+)\s+(?P<margin>[\d]+)"
            toppartitions = {}
            for out in output.split('\n\n'):
                partition = OrderedDict()
                sampler_data = re.match(pattern1, out, re.MULTILINE)
                sampler_data = sampler_data.groupdict()
                partitions = re.findall(pattern2, out, re.MULTILINE)
                for val in partitions:
                    partition.update({val[0]: {'count': val[1], 'margin': val[2]}})
                sampler_data.update({'partitions': partition})
                toppartitions[sampler_data.pop('sampler')] = sampler_data
            return toppartitions

        def generate_random_parameters_values():  # pylint: disable=invalid-name
            ks_cf_list = get_non_system_ks_cf_list(self.target_node)
            if not ks_cf_list:
                raise UnsupportedNemesis('User-defined Keyspace and ColumnFamily are not found.')
            try:
                ks, cf = random.choice(ks_cf_list).split('.')
            except IndexError as details:
                self.log.error('User-defined Keyspace and ColumnFamily are not found %s.', ks_cf_list)
                self.log.debug('Error during choosing keyspace and columnfamily %s', details)
                raise Exception('User-defined Keyspace and ColumnFamily are not found. \n{}'.format(details))
            return {
                'toppartition': str(random.randint(5, 20)),
                'samplers': random.choice(['writes', 'reads', 'writes,reads']),
                'capacity': str(random.randint(100, 1024)),
                'ks': ks,
                'cf': cf,
                'duration': str(random.randint(1000, 10000))
            }

        self._set_current_disruption("ShowTopPartitions")
        # workaround for issue #4519
        self.target_node.run_nodetool('cfstats')

        args = generate_random_parameters_values()
        sub_cmd_args = "{ks} {cf} {duration} -s {capacity} -k {toppartition} -a {samplers}".format(**args)

        result = self.target_node.run_nodetool(sub_cmd='toppartitions', args=sub_cmd_args)

        toppartition_result = _parse_toppartitions_output(result.stdout)
        for sampler in args['samplers'].split(','):
            sampler = sampler.upper()
            self.tester.assertIn(sampler, toppartition_result,
                                 msg="{} sampler not found in result".format(sampler))
            self.tester.assertTrue(toppartition_result[sampler]['toppartitions'] == args['toppartition'],
                                   msg="Wrong expected and actual top partitions number for {} sampler".format(sampler))
            self.tester.assertTrue(toppartition_result[sampler]['capacity'] == args['capacity'],
                                   msg="Wrong expected and actual capacity number for {} sampler".format(sampler))
            self.tester.assertLessEqual(len(toppartition_result[sampler]['partitions'].keys()),
                                        int(args['toppartition']),
                                        msg="Wrong number of requested and expected toppartitions for {} sampler".format(
                                            sampler))

    def get_rate_limit_for_network_disruption(self) -> Optional[str]:
        if not self.monitoring_set.nodes:
            return None

        # get the last 10min avg network bandwidth used, and limit  30% to 70% of it
        prometheus_stats = PrometheusDBStats(host=self.monitoring_set.nodes[0].external_address)
        query = 'avg(irate(node_network_receive_bytes_total{instance=~".*?%s.*?", device="eth0"}[60s]))' % \
                self.target_node.ip_address
        now = time.time()
        results = prometheus_stats.query(query=query, start=now - 600, end=now)
        assert results, "no results for node_network_receive_bytes_total metric in Prometheus "
        avg_bitrate_per_node = max([float(avg_rate) for _, avg_rate in results[0]["values"]])
        avg_mpbs_per_node = avg_bitrate_per_node / 1024 / 1024

        if avg_mpbs_per_node > 10:
            min_limit = int(round(avg_mpbs_per_node * 0.30))
            max_limit = int(round(avg_mpbs_per_node * 0.70))
            rate_limit_suffix = "mbps"
        else:
            avg_kbps_per_node = avg_bitrate_per_node / 1024
            min_limit = int(round(avg_kbps_per_node * 0.30))
            max_limit = int(round(avg_kbps_per_node * 0.70))
            rate_limit_suffix = "kbps"

        return "{}{}".format(random.randrange(min_limit, max_limit), rate_limit_suffix)

    def disrupt_network_random_interruptions(self):  # pylint: disable=invalid-name
        # pylint: disable=too-many-locals
        self._set_current_disruption('NetworkRandomInterruption')
        if not self.cluster.extra_network_interface:
            raise UnsupportedNemesis("for this nemesis to work, you need to set `extra_network_interface: True`")

        rate_limit: Optional[str] = self.get_rate_limit_for_network_disruption()
        if not rate_limit:
            self.log.warn("NetworkRandomInterruption won't limit network bandwith due to lack of monitoring nodes.")

        # random packet loss - between 1% - 15%
        loss_percentage = random.randrange(1, 15)

        # random packet corruption - between 1% - 15%
        corrupt_percentage = random.randrange(1, 15)

        # random packet delay - between 1s - 30s
        delay_in_secs = random.randrange(1, 30)

        list_of_tc_options = [
            ("NetworkRandomInterruption_{}%-loss".format(loss_percentage), "--loss {}%".format(loss_percentage)),
            ("NetworkRandomInterruption_{}%-corrupt".format(corrupt_percentage),
             "--corrupt {}%".format(corrupt_percentage)),
            ("NetworkRandomInterruption_{}sec-delay".format(delay_in_secs),
             "--delay {}s --delay-distro 500ms".format(delay_in_secs))]
        if rate_limit:
            list_of_tc_options.append(
                ("NetworkRandomInterruption_{}-limit".format(rate_limit), "--rate {}".format(rate_limit)))

        list_of_timeout_options = [10, 60, 120, 300, 500]
        option_name, selected_option = random.choice(list_of_tc_options)
        wait_time = random.choice(list_of_timeout_options)

        self._set_current_disruption(option_name)
        self.log.debug("NetworkRandomInterruption: [%s] for %dsec", selected_option, wait_time)
        self.target_node.traffic_control(None)
        try:
            self.target_node.traffic_control(selected_option)
            time.sleep(wait_time)
        finally:
            self.target_node.traffic_control(None)

    def disrupt_network_block(self):
        self._set_current_disruption('BlockNetwork')
        if not self.cluster.extra_network_interface:
            raise UnsupportedNemesis("for this nemesis to work, you need to set `extra_network_interface: True`")

        selected_option = "--loss 100%"
        list_of_timeout_options = [10, 60, 120, 300, 500]
        wait_time = random.choice(list_of_timeout_options)
        self.log.debug("BlockNetwork: [%s] for %dsec", selected_option, wait_time)
        self.target_node.traffic_control(None)
        try:
            self.target_node.traffic_control(selected_option)
            time.sleep(wait_time)
        finally:
            self.target_node.traffic_control(None)

    # Temporary disable due to  https://github.com/scylladb/scylla/issues/6522
    def _disrupt_network_reject_inter_node_communication(self):
        """
        Generates random firewall rule to drop/reject packets for inter-node communications, port 7000 and 7001
        """
        name = 'RejectInterNodeNetwork'
        textual_matching_rule, matching_rule = self._iptables_randomly_get_random_matching_rule()
        textual_pkt_action, pkt_action = self._iptables_randomly_get_disrupting_target()
        wait_time = random.choice([10, 60, 120, 300, 500])
        self._set_current_disruption(f'{name}: {textual_matching_rule} that belongs to '
                                     'inter node communication connections (port=7000 and 7001) will be'
                                     f' {textual_pkt_action} for {wait_time}s')

        # because of https://github.com/scylladb/scylla/issues/5802, we ignore YCSB client errors here
        with ignore_alternator_client_errors():
            return self._run_commands_wait_and_cleanup(
                self.target_node,
                name=name,
                start_commands=[
                    f'sudo iptables -t filter -A INPUT -p tcp --dport 7000 {matching_rule} -j {pkt_action}',
                    f'sudo iptables -t filter -A INPUT -p tcp --dport 7001 {matching_rule} -j {pkt_action}'
                ],
                cleanup_commands=[
                    f'sudo iptables -t filter -D INPUT -p tcp --dport 7000 {matching_rule} -j {pkt_action}',
                    f'sudo iptables -t filter -D INPUT -p tcp --dport 7001 {matching_rule} -j {pkt_action}'
                ],
                wait_time=wait_time
            )

    def disrupt_network_reject_node_exporter(self):
        """
        Generates random firewall rule to drop/reject packets for node exporter connections, port 9100
        """
        name = 'RejectNodeExporterNetwork'
        textual_matching_rule, matching_rule = self._iptables_randomly_get_random_matching_rule()
        textual_pkt_action, pkt_action = self._iptables_randomly_get_disrupting_target()
        wait_time = random.choice([10, 60, 120, 300, 500])
        self._set_current_disruption(f'{name}: {textual_matching_rule} that belongs to '
                                     f'node-exporter(port=9100) connections will be {textual_pkt_action} for {wait_time}s')
        return self._run_commands_wait_and_cleanup(
            self.target_node,
            name=name,
            start_commands=[f'sudo iptables -t filter -A INPUT -p tcp --dport 9100 {matching_rule} -j {pkt_action}'],
            cleanup_commands=[f'sudo iptables -t filter -D INPUT -p tcp --dport 9100 {matching_rule} -j {pkt_action}'],
            wait_time=wait_time
        )

    def disrupt_network_reject_thrift(self):
        """
        Generates random firewall rule to drop/reject packets for thrift connections, port 9100
        """
        name = 'RejectThriftNetwork'
        textual_matching_rule, matching_rule = self._iptables_randomly_get_random_matching_rule()
        textual_pkt_action, pkt_action = self._iptables_randomly_get_disrupting_target()
        wait_time = random.choice([10, 60, 120, 300, 500])
        self._set_current_disruption(f'{name}: {textual_matching_rule} that belongs to '
                                     f'Thrift(port=9160) connections will be {textual_pkt_action} for {wait_time}s')
        return self._run_commands_wait_and_cleanup(
            self.target_node,
            name=name,
            start_commands=[f'sudo iptables -t filter -A INPUT -p tcp --dport 9160 {matching_rule} -j {pkt_action}'],
            cleanup_commands=[f'sudo iptables -t filter -D INPUT -p tcp --dport 9160 {matching_rule} -j {pkt_action}'],
            wait_time=wait_time
        )

    @staticmethod
    def _iptables_randomly_get_random_matching_rule():
        """
        Randomly generates iptables matching rule to match packets in random manner
        """
        match_type = random.choice(
            ['statistic', 'statistic', 'statistic', 'limit', 'limit', 'limit', '']
            #  Make no matching rule less probable
        )

        if match_type == 'statistic':
            mode = random.choice(['random', 'nth'])
            if match_type == 'random':
                probability = random.choice(['0.0001', '0.001', '0.01', '0.1', '0.3', '0.6', '0.8', '0.9'])
                return f'randomly chosen packet with {probability} probability', \
                    f'-m statistic --mode {mode} --probability {probability}'
            elif match_type == 'nth':
                every = random.choice(['2', '4', '8', '16', '32', '64', '128'])
                return f'every {every} packet', \
                    f'-m statistic --mode {mode} --every {every} --packet 0'
        elif match_type == 'limit':
            period = random.choice(['second', 'minute'])
            pkts_per_period = random.choice({
                'second': [1, 5, 10],
                'minute': [2, 10, 40, 80]
            }.get(period))
            return f'string of {pkts_per_period} very first packets every {period}', \
                f'-m limit --limit {pkts_per_period}/{period}'
        elif match_type == 'connbytes':
            bytes_from = random.choice(['100', '200', '400', '800', '1600', '3200', '6400', '12800', '1280000'])
            return f'every packet from connection that total byte counter exceeds {bytes_from}', \
                f'-m connbytes --connbytes-mode bytes --connbytes-dir both --connbytes {bytes_from}'
        return 'every packet', ''

    @staticmethod
    def _iptables_randomly_get_disrupting_target():
        """
        Randomly generates iptables target that can cause disruption
        """
        target_type = random.choice(['REJECT', 'DROP'])
        if target_type == 'REJECT':
            reject_with = random.choice([
                'icmp-net-unreachable',
                'icmp-host-unreachable',
                'icmp-port-unreachable',
                'icmp-proto-unreachable',
                'icmp-net-prohibited',
                'icmp-host-prohibited',
                'icmp-admin-prohibited'
            ])
            return f'rejected with {reject_with}',\
                f'{target_type} --reject-with {reject_with}'
        return f'dropped', \
            f'{target_type}'

    def _run_commands_wait_and_cleanup(  # pylint: disable=too-many-arguments
            self, node, name: str, start_commands: List[str],
            cleanup_commands: List[str] = None, wait_time: int = 0):
        """
        Runs command/commands on target node wait and run cleanup commands
            :param node: target node
            :param name: Name of Nemesis for logging
            :param start_commands: commands to run on start
            :param cleanup_commands: commands to run to cleanup
            :param wait_time: waiting time
        """
        cmd_executed = {}
        if cleanup_commands is None:
            cleanup_commands = []
        for cmd_num, cmd in enumerate(start_commands):
            try:
                node.remoter.run(cmd)
                self.log.debug(f"{name}: executed: {cmd}")
                cmd_executed[cmd_num] = True
                if wait_time:
                    time.sleep(wait_time)
            except Exception as exc:  # pylint: disable=broad-except
                cmd_executed[cmd_num] = False
                self.log.error(
                    f"{name}: failed to execute start command "
                    f"{cmd} on node {node} due to the following error: {str(exc)}")
        if not cmd_executed:
            return
        for cmd_num, cmd in enumerate(cleanup_commands):
            try:
                node.remoter.run(cmd)
            except Exception as exc:  # pylint: disable=broad-except
                self.log.debug(f"{name}: failed to execute cleanup command "
                               f"{cmd} on node {node} due to the following error: {str(exc)}")

    def disrupt_network_start_stop_interface(self):  # pylint: disable=invalid-name
        self._set_current_disruption('StopStartNetworkInterfaces')
        if not self.cluster.extra_network_interface:
            raise UnsupportedNemesis("for this nemesis to work, you need to set `extra_network_interface: True`")

        list_of_timeout_options = [10, 60, 120, 300, 500]
        wait_time = random.choice(list_of_timeout_options)
        self.log.debug("Taking down eth1 for %dsec", wait_time)

        try:
            self.target_node.remoter.run("sudo /sbin/ifdown eth1")
            time.sleep(wait_time)
        finally:
            self.target_node.remoter.run("sudo /sbin/ifup eth1")

    def break_streaming_task_and_rebuild(self, task='decommission'):  # pylint: disable=too-many-statements
        """
        Stop streaming task in middle and rebuild the data on the node.
        """
        def decommission_post_action():
            decommission_done = self.target_node.search_system_log(
                'DECOMMISSIONING: done', start_from_beginning=True, publish_events=False, severity=Severity.WARNING)

            ips = []
            seed_nodes = [node for node in self.cluster.nodes if node.is_seed]
            status = self.cluster.get_nodetool_status(verification_node=seed_nodes[0])
            self.log.debug(status)
            for dc_info in status.values():
                try:
                    ips.extend(dc_info.keys())
                except Exception:  # pylint: disable=broad-except
                    self.log.debug(dc_info)

            if self.target_node.ip_address not in ips or decommission_done:
                self.log.error(
                    'The target node is decommission unexpectedly, decommission might complete before stopping it. Re-add a new node')
                self._terminate_cluster_node(self.target_node)
                new_node = self._add_and_init_new_cluster_node()
                new_node.running_nemesis = None
                return new_node
            return None

        def streaming_task_thread(nodetool_task='rebuild'):
            """
            Execute some nodetool command to start persistent streaming
            task: decommission | rebuild | repair
            """
            if nodetool_task in ['repair', 'rebuild']:
                self._destroy_data_and_restart_scylla()

            try:
                self.target_node.run_nodetool(nodetool_task)
            except Exception:  # pylint: disable=broad-except
                self.log.debug('%s is stopped' % nodetool_task)

        self.task_used_streaming = None
        streaming_thread = threading.Thread(target=streaming_task_thread, kwargs={'nodetool_task': task},
                                            name='StreamingThread')
        streaming_thread.start()

        def is_streaming_started():
            stream_pattern = "range_streamer - Unbootstrap starts|range_streamer - Rebuild starts"
            streaming_logs = self.target_node.search_system_log(
                stream_pattern, start_from_beginning=False, publish_events=False, severity=Severity.NORMAL)
            self.log.debug(streaming_logs)
            if streaming_logs:
                self.task_used_streaming = True

            # In latest master, repair always won't use streaming
            repair_logs = self.target_node.search_system_log(
                'repair - Repair 1 out of', start_from_beginning=False, publish_events=False, severity=Severity.NORMAL)
            self.log.debug(repair_logs)
            return len(streaming_logs) > 0 or len(repair_logs) > 0

        wait.wait_for(func=is_streaming_started, timeout=200, step=1,
                      text='Wait for streaming starts', throw_exc=False)
        self.log.debug('wait for random between 10s to 10m')
        time.sleep(random.randint(10, 600))

        self.log.info('Interrupt the task (%s) to trigger streaming error' % task)
        if random.randint(0, 1) == 0:
            self.log.debug('Interrupt the task by pkill')
            self.target_node.remoter.run('sudo pkill -9 -f %s' % task, ignore_status=True)
            self.log.debug("Stop background repair task by storage_service/force_terminate_repair API")
            with DbEventsFilter(type='DATABASE_ERROR', line="repair's stream failed: streaming::stream_exception",
                                node=self.target_node), \
                    DbEventsFilter(type='RUNTIME_ERROR', line='Can not find stream_manager', node=self.target_node), \
                    DbEventsFilter(type='RUNTIME_ERROR', line='is aborted', node=self.target_node), \
                    DbEventsFilter(type='RUNTIME_ERROR', line='Failed to repair', node=self.target_node):
                self.target_node.remoter.run(
                    'curl -X POST --header "Content-Type: application/json" --header "Accept: application/json" "http://127.0.0.1:10000/storage_service/force_terminate_repair"')
        else:
            self.log.debug('Interrupt the task by hard reboot')
            self.target_node.reboot(hard=True, verify_ssh=True)
        streaming_thread.join(60)

        new_node = decommission_post_action()

        if self.task_used_streaming:
            err = self.target_node.search_system_log(
                'streaming.*err', start_from_beginning=False, severity=Severity.ERROR)
            self.log.debug(err)
        else:
            self.log.debug(
                'Streaming is not used. In latest Scylla, it is optional to use streaming for rebuild and decommission, and repair will not use streaming.')
        self.log.info('Recover the target node by a final rebuild')
        if new_node:
            new_node.wait_db_up(verbose=True, timeout=300)
            new_node.run_nodetool('rebuild')
        else:
            self.target_node.wait_db_up(verbose=True, timeout=300)
            self.target_node.run_nodetool('rebuild')

    def disrupt_decommission_streaming_err(self):
        """
        Stop decommission in middle to trigger some streaming fails, then rebuild the data on the node.
        If the node is decommission unexpectedly, need to re-add a new node to cluster.
        """
        self._set_current_disruption('DecommissionStreamingErr')
        self.break_streaming_task_and_rebuild(task='decommission')

    def disrupt_rebuild_streaming_err(self):
        """
        Stop rebuild in middle to trigger some streaming fails, then rebuild the data on the node.
        """
        self._set_current_disruption('RebuildStreamingErr')
        self.break_streaming_task_and_rebuild(task='rebuild')

    def disrupt_repair_streaming_err(self):
        """
        Stop repair in middle to trigger some streaming fails, then rebuild the data on the node.
        """
        self._set_current_disruption('RepairStreamingErr')
        self.break_streaming_task_and_rebuild(task='repair')

    def _corrupt_data_file(self):
        """Randomly corrupt data file by dd"""
        ks_cfs = get_non_system_ks_cf_list(db_node=self.target_node)
        if not ks_cfs:
            raise UnsupportedNemesis(
                'Non-system keyspace and table are not found. Nemesis can\'t be run')

        # Corrupt data file
        data_file_pattern = self._choose_file_for_destroy(ks_cfs)
        res = self.target_node.remoter.run('sudo find {}-Data.db'.format(data_file_pattern))
        for sstable_file in res.stdout.split():
            result = self.target_node.remoter.run(
                'sudo dd if=/dev/urandom of={} count=1024'.format(sstable_file))
            self.log.debug('File {} was corrupted by dd'.format(sstable_file))

    def disable_disrupt_corrupt_then_scrub(self):

        # Flush data to sstable
        self.target_node.run_nodetool("flush")

        self.log.debug("Randomly corrupt sstable file")
        self._corrupt_data_file()

        self.log.debug("Rebuild sstable file by scrub, corrupted data file will be skipped.")
        for ks_cf in get_non_system_ks_cf_list(self.target_node):
            scrub_cmd = 'curl -s -X GET --header "Content-Type: application/json" --header ' \
                        '"Accept: application/json" "http://127.0.0.1:10000/storage_service/keyspace_scrub/{}?skip_corrupted=true"'.format(
                            ks_cf.split('.')[0])
            self.target_node.remoter.run(scrub_cmd)

        self.log.debug('Refreshing the cache by restart the node, and verify the rebuild sstable can be loaded successfully.')
        self.target_node.stop_scylla_server(verify_up=False, verify_down=True)
        self.target_node.start_scylla_server(verify_up=True, verify_down=False)

    def disrupt_grow_shrink_cluster(self):
        add_nodes_number = self.tester.params.get('nemesis_add_node_cnt')
        self.target_node.running_nemesis = None

        self._set_current_disruption("GrowCluster")
        self.log.info("Start grow cluster on %s nodes", add_nodes_number)
        for _ in range(add_nodes_number):
            self.metrics_srv.event_start('add_node')
            added_node = self._add_and_init_new_cluster_node()
            added_node.running_nemesis = None
            self.metrics_srv.event_stop('add_node')
            self.log.info("New node added %s", added_node.name)
        self.log.info("Finish cluster grow")

        time.sleep(self.interval)

        self._set_current_disruption("ShrinkCLuster")
        self.log.info("Start shrink cluster on %s nodes", add_nodes_number)
        for _ in range(add_nodes_number):
            self.set_target_node()
            self.log.info("Next node will be removed %s", self.target_node)
            self.metrics_srv.event_start('del_node')
            try:
                self.cluster.decommission(self.target_node)
            finally:
                self.metrics_srv.event_stop('del_node')

        self.log.info("Finish cluster shrink. Current number of nodes %s", len(self.cluster.nodes))

    def disrupt_hot_reloading_internode_certificate(self):
        '''
        https://github.com/scylladb/scylla/issues/6067
        Scylla has the ability to hot reload SSL certificates.
        This test will create and reload new certificates for the inter node communication.
        '''
        self._set_current_disruption('HotReloadInternodeCertificate')
        if not self.cluster.params.get('server_encrypt', None):
            raise UnsupportedNemesis('Server Encryption is not enabled, hence skipping')

        @retrying(allowed_exceptions=LogContentNotFound)
        def check_ssl_reload_log(target_node, file_path, since_time):
            msg = target_node.remoter.run(f'journalctl -u scylla-server --since="{since_time}" | '
                                          f'grep Reload | grep {file_path}', ignore_status=True)
            if not msg.stdout:
                raise LogContentNotFound('Reload SSL message not found in node log')
            return msg.stdout

        ssl_files_location = '/etc/scylla/ssl_conf'
        in_place_crt = self.target_node.remoter.run(f"cat {os.path.join(ssl_files_location, 'db.crt')}",
                                                    ignore_status=True).stdout
        update_certificates()
        time_now = datetime.datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S")
        for node in self.cluster.nodes:
            node.remoter.send_files(src='data_dir/ssl_conf/db.crt', dst='/tmp')
        for node in self.cluster.nodes:
            node.remoter.run(f"sudo cp -f /tmp/db.crt {ssl_files_location}")
        for node in self.cluster.nodes:
            new_crt = node.remoter.run(f"cat {os.path.join(ssl_files_location, 'db.crt')}").stdout
            if in_place_crt == new_crt:
                raise Exception('The CRT file was not replaced with the new one')
            reload = check_ssl_reload_log(target_node=node, file_path=os.path.join(ssl_files_location, 'db.crt'),
                                          since_time=time_now)

            if not reload:
                raise Exception('SSL auto Reload did not happen')

        self.log.info('hot reloading internode ssl nemesis finished')


class NotSpotNemesis(Nemesis):
    def set_target_node(self):

        if isinstance(self.cluster, ScyllaAWSCluster):
            non_seed_nodes = [node for node in self.cluster.nodes
                              if not node.is_seed and
                              not node.is_spot and
                              not node.running_nemesis]
            if non_seed_nodes:
                self.target_node = random.choice(non_seed_nodes)

        else:
            super(NotSpotNemesis, self).set_target_node()

        self.log.info('Current Target: %s', self.target_node)

    def disrupt(self):
        raise NotImplementedError()


def log_time_elapsed_and_status(method):  # pylint: disable=too-many-statements
    """
    Log time elapsed for method to run

    :param method: Remote method to wrap.
    :return: Wrapped method.
    """

    def data_validation_prints(args):
        try:
            if hasattr(args[0].tester, 'data_validator') and args[0].tester.data_validator:
                with args[0].tester.cql_connection_patient(args[0].cluster.nodes[0], keyspace=args[0].tester.data_validator.keyspace_name) as session:
                    args[0].tester.data_validator.validate_range_not_expected_to_change(session, during_nemesis=True)
                    args[0].tester.data_validator.validate_range_expected_to_change(session, during_nemesis=True)
                    args[0].tester.data_validator.validate_deleted_rows(session, during_nemesis=True)
        except Exception as err:  # pylint: disable=broad-except
            args[0].log.debug(f'Data validator error: {err}')

    def wrapper(*args, **kwargs):  # pylint: disable=too-many-statements
        # pylint: disable=too-many-locals
        args[0].cluster.check_cluster_health()
        num_nodes_before = len(args[0].cluster.nodes)
        start_time = time.time()
        args[0].log.debug('Start disruption at `%s`', datetime.datetime.fromtimestamp(start_time))
        class_name = args[0].get_class_name()
        if class_name.find('Chaos') < 0:
            args[0].metrics_srv.event_start(class_name)
        result = None
        status = True
        log_info = {
            'operation': args[0].current_disruption,
            'start': int(start_time),
            'end': 0,
            'duration': 0,
            'node': str(args[0].target_node),
            'type': 'end',
        }
        # TODO: Temporary print. Will be removed later
        data_validation_prints(args=args)

        try:
            result = method(*args, **kwargs)
        except UnsupportedNemesis as exp:
            log_info.update({'type': 'skipped', 'skip_reason': str(exp)})
            logging.info("skipping %s", args[0].get_disrupt_name())
            logging.info("cause of: %s", str(exp))
            raise

        except Exception as details:  # pylint: disable=broad-except
            details = str(details)
            args[0].error_list.append(details)
            args[0].log.error('Unhandled exception in method %s', method, exc_info=True)
            log_info.update({'error': details, 'full_traceback': traceback.format_exc()})
            status = False
        finally:
            end_time = time.time()
            time_elapsed = int(end_time - start_time)
            log_info.update({
                'end': int(end_time),
                'duration': time_elapsed,
            })
            args[0].duration_list.append(time_elapsed)
            args[0].operation_log.append(log_info)
            args[0].log.debug('%s duration -> %s s', args[0].current_disruption, time_elapsed)

            if class_name.find('Chaos') < 0:
                args[0].metrics_srv.event_stop(class_name)
            disrupt = args[0].get_disrupt_name()
            del log_info['operation']

            args[0].update_stats(disrupt, status, log_info)
            DisruptionEvent(name=disrupt, status=status, **log_info)
            args[0].cluster.check_cluster_health()
            num_nodes_after = len(args[0].cluster.nodes)
            if num_nodes_before != num_nodes_after:
                args[0].log.error('num nodes before %s and nodes after %s does not match' %
                                  (num_nodes_before, num_nodes_after))
            # TODO: Temporary print. Will be removed later
            data_validation_prints(args=args)
        return result

    return wrapper


class SslHotReloadingNemesis(Nemesis):
    disruptive = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_hot_reloading_internode_certificate()


class NoOpMonkey(Nemesis):

    @log_time_elapsed_and_status
    def disrupt(self):
        time.sleep(300)


class GrowShrinkClusterNemesis(Nemesis):
    disruptive = True

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_grow_shrink_cluster()


class StopWaitStartMonkey(Nemesis):
    disruptive = True

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_stop_wait_start_scylla_server(600)


class StopStartMonkey(Nemesis):
    disruptive = True

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_stop_start_scylla_server()


class RestartThenRepairNodeMonkey(NotSpotNemesis):
    disruptive = True

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_restart_then_repair_node()


class MultipleHardRebootNodeMonkey(Nemesis):
    disruptive = True

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_multiple_hard_reboot_node()


class HardRebootNodeMonkey(Nemesis):
    disruptive = True

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_hard_reboot_node()


class SoftRebootNodeMonkey(Nemesis):
    disruptive = True

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_soft_reboot_node()


class DrainerMonkey(Nemesis):
    disruptive = True

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_nodetool_drain()


class CorruptThenRepairMonkey(Nemesis):
    disruptive = True

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_destroy_data_then_repair()


class CorruptThenRebuildMonkey(Nemesis):
    disruptive = True

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_destroy_data_then_rebuild()


class DecommissionMonkey(Nemesis):
    disruptive = True

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_nodetool_decommission()


class NoCorruptRepairMonkey(Nemesis):
    disruptive = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_no_corrupt_repair()


class MajorCompactionMonkey(Nemesis):
    disruptive = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_major_compaction()


class RefreshMonkey(Nemesis):
    disruptive = False
    run_with_gemini = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_nodetool_refresh()


class RefreshBigMonkey(Nemesis):
    disruptive = False
    run_with_gemini = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_nodetool_refresh(big_sstable=True, skip_download=False)


class EnospcMonkey(Nemesis):
    disruptive = True

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_nodetool_enospc()


class EnospcAllNodesMonkey(Nemesis):
    disruptive = True

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_nodetool_enospc(all_nodes=True)


class NodeToolCleanupMonkey(Nemesis):
    disruptive = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_nodetool_cleanup()


class TruncateMonkey(Nemesis):
    disruptive = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_truncate()


class DeleteByPartitionsMonkey(Nemesis):
    disruptive = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_delete_10_full_partitions()


class DeleteByRowsRangeMonkey(Nemesis):
    disruptive = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_delete_by_rows_range()


class ChaosMonkey(Nemesis):

    @log_time_elapsed_and_status
    def disrupt(self):
        self.call_random_disrupt_method()


class LimitedChaosMonkey(Nemesis):

    @log_time_elapsed_and_status
    def disrupt(self):
        # Limit the nemesis scope:
        #  - NodeToolCleanupMonkey
        #  - DecommissionMonkey
        #  - DrainerMonkey
        #  - RefreshMonkey
        #  - StopStartMonkey
        #  - MajorCompactionMonkey
        #  - ModifyTableMonkey
        #  - EnospcMonkey
        #  - StopWaitStartMonkey
        #  - HardRebootMonkey
        #  - SoftRebootMonkey
        #  - TruncateMonkey
        #  - ToppartitionsMonkey
        #  - MgmtRepair
        #  - NoCorruptRepairMonkey
        #  - SnapshotOperations
        #  - AbortRepairMonkey
        #  - MgmtBackup
        #  - AddDropColumnMonkey
        self.call_random_disrupt_method(disrupt_methods=['disrupt_nodetool_cleanup', 'disrupt_nodetool_decommission',
                                                         'disrupt_nodetool_drain', 'disrupt_nodetool_refresh',
                                                         'disrupt_stop_start_scylla_server', 'disrupt_major_compaction',
                                                         'disrupt_modify_table', 'disrupt_nodetool_enospc',
                                                         'disrupt_stop_wait_start_scylla_server',
                                                         'disrupt_hard_reboot_node', 'disrupt_soft_reboot_node',
                                                         'disrupt_truncate', 'disrupt_show_toppartitions',
                                                         'disrupt_mgmt_repair_cli', 'disrupt_no_corrupt_repair',
                                                         'disrupt_snapshot_operations', 'disrupt_abort_repair',
                                                         'disrupt_mgmt_backup', 'disrupt_add_drop_column'])


class ScyllaCloudLimitedChaosMonkey(Nemesis):

    @log_time_elapsed_and_status
    def disrupt(self):
        # Limit the nemesis scope to only one relevant to scylla cloud, where we defined we don't have AWS api access:
        self.call_random_disrupt_method(disrupt_methods=['disrupt_nodetool_cleanup',
                                                         'disrupt_nodetool_drain', 'disrupt_nodetool_refresh',
                                                         'disrupt_stop_start_scylla_server', 'disrupt_major_compaction',
                                                         'disrupt_modify_table', 'disrupt_nodetool_enospc',
                                                         'disrupt_stop_wait_start_scylla_server',
                                                         'disrupt_soft_reboot_node',
                                                         'disrupt_truncate'])


class AllMonkey(Nemesis):

    @log_time_elapsed_and_status
    def disrupt(self):
        self.call_random_disrupt_method(predefined_sequence=True)


class MdcChaosMonkey(Nemesis):

    @log_time_elapsed_and_status
    def disrupt(self):
        self.call_random_disrupt_method(
            disrupt_methods=['disrupt_destroy_data_then_repair', 'disrupt_no_corrupt_repair',
                             'disrupt_nodetool_decommission'])


class UpgradeNemesis(Nemesis):

    # # upgrade a single node
    # def upgrade_node(self, node):
    #     repo_file = self.cluster.params.get('repo_file', None,  'scylla.repo.upgrade')
    #     new_version = self.cluster.params.get('new_version', None,  '')
    #     upgrade_node_packages = self.cluster.params.get('upgrade_node_packages')
    #     self.log.info('Upgrading a Node')
    #
    #     # We assume that if update_db_packages is not empty we install packages from there.
    #     # In this case we don't use upgrade based on repo_file(ignored sudo yum update scylla...)
    #     orig_ver = node.remoter.run('rpm -qa scylla-server')
    #     if upgrade_node_packages:
    #         # update_scylla_packages
    #         node.remoter.send_files(upgrade_node_packages, '/tmp/scylla', verbose=True)
    #         # node.remoter.run('sudo yum update -y --skip-broken', connect_timeout=900)
    #         node.remoter.run('sudo yum install python34-PyYAML -y')
    #         # replace the packages
    #         node.remoter.run('rpm -qa scylla\*')
    #         node.run_nodetool("snapshot")
    #         # update *development* packages
    #         node.remoter.run('sudo rpm -UvhR --oldpackage /tmp/scylla/*development*', ignore_status=True)
    #         # and all the rest
    #         node.remoter.run('sudo rpm -URvh --replacefiles /tmp/scylla/*.rpm | true')
    #         node.remoter.run('rpm -qa scylla\*')
    #     elif repo_file:
    #         scylla_repo = get_data_dir_path(repo_file)
    #         node.remoter.send_files(scylla_repo, '/tmp/scylla.repo', verbose=True)
    #         node.remoter.run('sudo cp /etc/yum.repos.d/scylla.repo ~/scylla.repo-backup')
    #         node.remoter.run('sudo cp /tmp/scylla.repo /etc/yum.repos.d/scylla.repo')
    #         # backup the data
    #         node.remoter.run('sudo cp /etc/scylla/scylla.yaml /etc/scylla/scylla.yaml-backup')
    #         node.run_nodetool("snapshot")
    #         node.remoter.run('sudo chown root.root /etc/yum.repos.d/scylla.repo')
    #         node.remoter.run('sudo chmod 644 /etc/yum.repos.d/scylla.repo')
    #         node.remoter.run('sudo yum clean all')
    #         ver_suffix = '-{}'.format(new_version) if new_version else ''
    #         node.remoter.run('sudo yum install scylla{0} scylla-server{0} scylla-jmx{0} scylla-tools{0}'
    #                          ' scylla-conf{0} scylla-kernel-conf{0} scylla-debuginfo{0} -y'.format(ver_suffix))
    #     # flush all memtables to SSTables
    #     node.run_nodetool("drain", timeout=3600, coredump_on_timeout=True)
    #     node.remoter.run('sudo systemctl restart scylla-server.service')
    #     node.wait_db_up(verbose=True)
    #     new_ver = node.remoter.run('rpm -qa scylla-server')
    #     if orig_ver == new_ver:
    #         self.log.error('scylla-server version isn\'t changed')

    @log_time_elapsed_and_status
    def disrupt(self):
        self.log.info('Upgrade Nemesis begin')
        # get the number of nodes
        nodes_num = len(self.cluster.nodes)
        # prepare an array containing the indexes
        indexes = list(range(nodes_num))
        # shuffle it so we will upgrade the nodes in a
        # random order
        random.shuffle(indexes)

        # upgrade all the nodes in random order
        for i in indexes:
            node = self.cluster.nodes[i]
            self.upgrade_node(node)  # pylint: disable=no-member

        self.log.info('Upgrade Nemesis end')


class UpgradeNemesisOneNode(UpgradeNemesis):

    @log_time_elapsed_and_status
    def disrupt(self):
        self.log.info('UpgradeNemesisOneNode begin')
        self.upgrade_node(self.cluster.node_to_upgrade)  # pylint: disable=no-member

        self.log.info('UpgradeNemesisOneNode end')


class RollbackNemesis(Nemesis):

    # rollback a single node
    def rollback_node(self, node):
        self.log.info('Rollbacking a Node')
        orig_ver = node.remoter.run('rpm -qa scylla-server')
        node.remoter.run('sudo cp ~/scylla.repo-backup /etc/yum.repos.d/scylla.repo')
        # backup the data
        node.run_nodetool("snapshot")
        node.remoter.run('sudo chown root.root /etc/yum.repos.d/scylla.repo')
        node.remoter.run('sudo chmod 644 /etc/yum.repos.d/scylla.repo')
        node.remoter.run('sudo yum clean all')
        node.remoter.run(
            'sudo yum downgrade scylla scylla-server scylla-jmx scylla-tools scylla-conf scylla-kernel-conf scylla-debuginfo -y')
        # flush all memtables to SSTables
        node.run_nodetool("drain", timeout=3600, coredump_on_timeout=True)
        node.remoter.run('sudo cp {0}-backup {0}'.format(SCYLLA_YAML_PATH))
        node.remoter.run('sudo systemctl restart scylla-server.service')
        node.wait_db_up(verbose=True)
        new_ver = node.remoter.run('rpm -qa scylla-server')
        self.log.debug('original scylla-server version is %s, latest: %s' % (orig_ver, new_ver))
        if orig_ver == new_ver:
            raise ValueError('scylla-server version isn\'t changed')

    @log_time_elapsed_and_status
    def disrupt(self):
        self.log.info('Rollback Nemesis begin')
        # get the number of nodes
        nodes_num = len(self.cluster.nodes)
        # prepare an array containing the indexes
        indexes = list(range(nodes_num))
        # shuffle it so we will rollback the nodes in a
        # random order
        random.shuffle(indexes)

        # rollback all the nodes in random order
        for i in indexes:
            node = self.cluster.nodes[i]
            self.rollback_node(node)

        self.log.info('Rollback Nemesis end')


class ModifyTableMonkey(Nemesis):
    disruptive = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_modify_table()


class AddDropColumnMonkey(Nemesis):
    disruptive = False
    run_with_gemini = False
    networking = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_add_drop_column()


class ToggleTableIcsMonkey(Nemesis):

    @log_time_elapsed_and_status
    def disrupt(self):
        self.call_random_disrupt_method(
            disrupt_methods=['disrupt_toggle_table_ics', 'disrupt_hard_reboot_node'])


class MgmtBackup(Nemesis):
    disruptive = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_mgmt_backup()


class MgmtRepair(Nemesis):
    disruptive = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.log.info('disrupt_mgmt_repair_cli Nemesis begin')
        self.disrupt_mgmt_repair_cli()
        self.log.info('disrupt_mgmt_repair_cli Nemesis end')
        # For Manager APIs test, use: self.disrupt_mgmt_repair_api()


class AbortRepairMonkey(Nemesis):
    disruptive = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_abort_repair()


class NodeTerminateAndReplace(Nemesis):
    disruptive = True

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_terminate_and_replace_node()


class ValidateHintedHandoffShortDowntime(Nemesis):
    disruptive = True

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_validate_hh_short_downtime()


class SnapshotOperations(Nemesis):
    disruptive = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_snapshot_operations()


class NodeRestartWithResharding(Nemesis):
    disruptive = True

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_restart_with_resharding()


class TopPartitions(Nemesis):
    disruptive = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_show_toppartitions()


class RandomInterruptionNetworkMonkey(Nemesis):
    disruptive = True
    networking = True
    run_with_gemini = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_network_random_interruptions()


class BlockNetworkMonkey(Nemesis):
    disruptive = True
    networking = True
    run_with_gemini = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_network_block()

# Temporary disable due to  https://github.com/scylladb/scylla/issues/6522
# class RejectInterNodeNetworkMonkey(Nemesis):
#     disruptive = True
#     networking = True
#     run_with_gemini = False
#
#     @log_time_elapsed_and_status
#     def disrupt(self):
#         self.disrupt_network_reject_inter_node_communication()


class RejectNodeExporterNetworkMonkey(Nemesis):
    disruptive = True
    networking = True
    run_with_gemini = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_network_reject_node_exporter()


class RejectThriftNetworkMonkey(Nemesis):
    disruptive = True
    networking = True
    run_with_gemini = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_network_reject_thrift()


class StopStartInterfacesNetworkMonkey(Nemesis):
    disruptive = True
    networking = True
    run_with_gemini = False

    @log_time_elapsed_and_status
    def disrupt(self):
        self.disrupt_network_start_stop_interface()


class DisruptiveMonkey(Nemesis):
    # Limit the nemesis scope:
    #  - ValidateHintedHandoffShortDowntime
    #  - CorruptThenRepairMonkey
    #  - CorruptThenRebuildMonkey
    #  - RestartThenRepairNodeMonkey
    #  - StopStartMonkey
    #  - MultipleHardRebootNodeMonkey
    #  - HardRebootNodeMonkey
    #  - SoftRebootNodeMonkey
    #  - StopWaitStartMonkey
    #  - NodeTerminateAndReplace
    #  - EnospcMonkey
    #  - DecommissionMonkey
    #  - NodeRestartWithResharding
    #  - DrainerMonkey

    def __init__(self, *args, **kwargs):
        super(DisruptiveMonkey, self).__init__(*args, **kwargs)
        self.disrupt_methods_list = self.get_list_of_disrupt_methods_for_nemesis_subclasses(disruptive=True)

    @log_time_elapsed_and_status
    def disrupt(self):
        self.call_random_disrupt_method(disrupt_methods=self.disrupt_methods_list)


class NonDisruptiveMonkey(Nemesis):
    # Limit the nemesis scope:
    #  - NodeToolCleanupMonkey
    #  - SnapshotOperations
    #  - RefreshMonkey
    #  - RefreshBigMonkey -
    #  - NoCorruptRepairMonkey
    #  - MgmtRepair

    def __init__(self, *args, **kwargs):
        super(NonDisruptiveMonkey, self).__init__(*args, **kwargs)
        self.disrupt_methods_list = self.get_list_of_disrupt_methods_for_nemesis_subclasses(disruptive=False)

    @log_time_elapsed_and_status
    def disrupt(self):
        self.call_random_disrupt_method(disrupt_methods=self.disrupt_methods_list)


class NetworkMonkey(Nemesis):
    # Limit the nemesis scope:
    #  - RandomInterruptionNetworkMonkey
    #  - StopStartInterfacesNetworkMonkey
    #  - BlockNetworkMonkey
    def __init__(self, *args, **kwargs):
        super(NetworkMonkey, self).__init__(*args, **kwargs)
        self.disrupt_methods_list = self.get_list_of_disrupt_methods_for_nemesis_subclasses(networking=True)

    @log_time_elapsed_and_status
    def disrupt(self):
        self.call_random_disrupt_method(disrupt_methods=self.disrupt_methods_list)


class GeminiChaosMonkey(Nemesis):
    # Limit the nemesis scope to use with gemini
    # - StopStartMonkey
    # - RestartThenRepairNodeMonkey
    def __init__(self, *args, **kwargs):
        super(GeminiChaosMonkey, self).__init__(*args, **kwargs)
        self.disrupt_methods_list = self.get_list_of_disrupt_methods_for_nemesis_subclasses(run_with_gemini=True)

    @log_time_elapsed_and_status
    def disrupt(self):
        self.call_random_disrupt_method(disrupt_methods=self.disrupt_methods_list)


class GeminiNonDisruptiveChaosMonkey(Nemesis):
    def __init__(self, *args, **kwargs):
        super(GeminiNonDisruptiveChaosMonkey, self).__init__(*args, **kwargs)
        run_with_gemini = set(self.get_list_of_disrupt_methods_for_nemesis_subclasses(run_with_gemini=True))
        non_disruptive = set(self.get_list_of_disrupt_methods_for_nemesis_subclasses(disruptive=False))
        self.disrupt_methods_list = run_with_gemini.intersection(non_disruptive)

    @log_time_elapsed_and_status
    def disrupt(self):
        self.call_random_disrupt_method(disrupt_methods=self.disrupt_methods_list)


# Disable unstable streaming err nemesises
#
# class DecommissionStreamingErrMonkey(Nemesis):
#
#     disruptive = True
#
#     @log_time_elapsed_and_status
#     def disrupt(self):
#         self.disrupt_decommission_streaming_err()
#
#
# class RebuildStreamingErrMonkey(Nemesis):
#
#     disruptive = True
#
#     @log_time_elapsed_and_status
#     def disrupt(self):
#         self.disrupt_rebuild_streaming_err()
#
#
# class RepairStreamingErrMonkey(Nemesis):
#
#     disruptive = True
#
#     @log_time_elapsed_and_status
#     def disrupt(self):
#         self.disrupt_repair_streaming_err()


RELATIVE_NEMESIS_SUBCLASS_LIST = [NotSpotNemesis]

DEPRECATED_LIST_OF_NEMESISES = [UpgradeNemesis, UpgradeNemesisOneNode, RollbackNemesis]

COMPLEX_NEMESIS = [NoOpMonkey, ChaosMonkey,
                   LimitedChaosMonkey,
                   ScyllaCloudLimitedChaosMonkey,
                   AllMonkey, MdcChaosMonkey,
                   DisruptiveMonkey, NonDisruptiveMonkey, GeminiNonDisruptiveChaosMonkey,
                   GeminiChaosMonkey, NetworkMonkey]


# TODO: https://trello.com/c/vwedwZK2/1881-corrupt-the-scrub-fails
# class CorruptThenScrubMonkey(Nemesis):
#     disruptive = False
#
#     @log_time_elapsed_and_status
#     def disrupt(self):
#         self.disable_disrupt_corrupt_then_scrub()
