test_duration: 1080 # ~5h prepare + 10h mixed + 3h margin

n_db_nodes: "6 6 6"
instance_type_db: 'i4i.xlarge'
n_loaders: "1 1 1"
instance_type_loader: 'c6i.4xlarge'
region_aware_loader: true

user_prefix: 'reproduce-issue'
append_scylla_yaml:
  # NOTE: per table metrics on the big count of tables has terrible performance
  # See: https://github.com/scylladb/scylla-monitoring/issues/2429
  # So, disable per table metrics
  enable_node_aggregated_table_metrics: false

nemesis_class_name: "SisyphusMonkey"
nemesis_selector: 'GrowShrinkClusterNemesis'
nemesis_seed: '777'
nemesis_interval: 15
nemesis_add_node_cnt: 3

# NOTE: prepare phase fails without nemesis. See https://github.com/scylladb/scylladb/issues/27566
#       So, it is better to keep prepare phase without nemesis to cover the bug case.
nemesis_during_prepare: false
# NOTE: skip enospc https://github.com/scylladb/scylla-cluster-tests/issues/12989
# NOTE: disable mgmt because we run disruptive nemesis with data validation.
# And if we do repairs, it takes too long making data validation exceed retries.
use_mgmt: false

root_disk_size_monitor: 120
root_disk_size_runner: 120

round_robin: true

# Schema is created automatically by SCT before the first latte run command.
# Schema parameters are passed via latte_schema_parameters.
latte_schema_parameters:
  replication_factor: 3
  compaction_strategy: "IncrementalCompactionStrategy"
  compression: "LZ4Compressor"
  create_all_keyspaces: "true"

# Phase 1: Populate all 130 tables (72 simple + 58 UDT) with initial data
prepare_write_cmd:
  # - >-
  #   latte run --tag populate -f populate_all
  #   --threads=10 --concurrency=1 --connections=1 --rate=5000 --consistency=LOCAL_QUORUM
  #   --warmup=0 --retries=3 --retry-interval=1s --request-timeout 60 --sampling 5s
  #   --validation-strategy=ignore --start-cycle=0
  #   -d 1000
  #   -P row_count_per_table=10
  #   -P gauss_mean=0
  #   -P gauss_stddev=0
  #   -P skip_write_errors=true
  #   data_dir/latte/scylladb_682.rn
  # - >-
  #   latte run --tag populate -f populate_all
  #   --threads=10 --concurrency=1 --connections=1 --rate=5000 --consistency=LOCAL_QUORUM
  #   --warmup=0 --retries=3 --retry-interval=1s --request-timeout 60 --sampling 5s
  #   --validation-strategy=ignore --start-cycle=100000000
  #   -d 1000
  #   -P row_count_per_table=10
  #   -P gauss_mean=0
  #   -P gauss_stddev=0
  #   -P skip_write_errors=true
  #   data_dir/latte/scylladb_682.rn
  # - >-
  #   latte run --tag populate -f populate_all
  #   --threads=10 --concurrency=1 --connections=1 --rate=5000 --consistency=LOCAL_QUORUM
  #   --warmup=0 --retries=3 --retry-interval=1s --request-timeout 60 --sampling 5s
  #   --validation-strategy=ignore --start-cycle=100000
  #   -d 1000
  #   -P row_count_per_table=10
  #   -P gauss_mean=0
  #   -P gauss_stddev=0
  #   -P skip_write_errors=true
  #   data_dir/latte/scylladb_682.rn
    # Mixed CRUD workload across all 130 tables (write:2, read:5, update:1, delete:1)
  - >-
    latte run --tag mixed-crud -f write_all
    --threads=10 --concurrency=1 --connections=1 --consistency=LOCAL_QUORUM --rate=2500
    --warmup=0 --retries=3 --retry-interval=5s,15s --request-timeout 600 --sampling 5s
    --validation-strategy=ignore
    -d 1000
    -P row_count_per_table=1000
    -P gauss_mean=100
    -P gauss_stddev=20000
    -P data_validation=false
    -P skip_write_errors=true
    data_dir/latte/scylladb_682.rn

  # Payment workflow simulation (3-table correlated writes: transactions → settlements → receipts)
  - >-
    latte run --tag payment-workflow -f payment_workflow
    --threads=10 --concurrency=1 --connections=1 --consistency=LOCAL_QUORUM --rate=2500
    --warmup=0 --retries=3 --retry-interval=5s,15s --request-timeout 600 --sampling 5s
    --validation-strategy=ignore
    -d 1000
    -P row_count_per_table=1000
    -P gauss_mean=1000
    -P gauss_stddev=20000
    -P data_validation=false
    -P skip_write_errors=true
    data_dir/latte/scylladb_682.rn

  # Windowed write/read/delete with shifting table windows
  # 40 tables active at once, shifting by 5 tables every 10 seconds
  - >-
    latte run --tag payment-workflow -f payment_workflow
    --threads=10 --concurrency=1 --connections=1 --consistency=LOCAL_QUORUM --rate=2500
    --warmup=0 --retries=3 --retry-interval=5s,15s --request-timeout 600 --sampling 5s
    --validation-strategy=ignore
    -d 1000
    -P row_count_per_table=1000
    -P gauss_mean=10000
    -P gauss_stddev=20000
    -P data_validation=false
    -P skip_write_errors=true
    data_dir/latte/scylladb_682.rn


# Phase 3: Advanced mixed workloads
# Command 1: Mixed write/read/update/delete across all tables with table windowing
# Command 2: Payment workflow simulation (transaction → settlement → receipt)
# Command 3: Windowed write/read with shifting table windows
stress_cmd:
  # Mixed CRUD workload across all 130 tables (write:2, read:5, update:1, delete:1)
  - >-
    latte run --tag mixed-crud -f write_all:3 -f read_all:5 -f update_all:1 -f delete_all:1
    --threads=14 --concurrency=4 --connections=1 --consistency=LOCAL_QUORUM --rate=1000
    --warmup=0 --retries=3 --retry-interval=5s,15s --request-timeout 600 --sampling 5s
    --validation-strategy=ignore
    -d 36000s
    -P row_count_per_table=20000
    -P gauss_mean=100
    -P gauss_stddev=20000
    -P data_validation=false
    -P skip_write_errors=true
    data_dir/latte/scylladb_682.rn

  # Payment workflow simulation (3-table correlated writes: transactions → settlements → receipts)
  - >-
    latte run --tag payment-workflow -f payment_workflow:1 -f read_all:3
    --threads=14 --concurrency=4 --connections=1 --consistency=LOCAL_QUORUM --rate=1000
    --warmup=0 --retries=3 --retry-interval=5s,15s --request-timeout 600 --sampling 5s
    --validation-strategy=ignore
    -d 36000s
    -P row_count_per_table=20000
    -P gauss_mean=1000
    -P gauss_stddev=20000
    -P data_validation=false
    -P skip_write_errors=true
    data_dir/latte/scylladb_682.rn

  # Windowed write/read/delete with shifting table windows
  # 40 tables active at once, shifting by 5 tables every 10 seconds
  - >-
    latte run --tag windowed -f write_windowed:2 -f read_windowed:5 -f delete_windowed:1
    --threads=14 --concurrency=4 --connections=1 --consistency=LOCAL_QUORUM --rate=1000
    --warmup=0 --retries=3 --retry-interval=5s,15s --request-timeout 600 --sampling 5s
    --validation-strategy=ignore
    -d 36000s
    -P row_count_per_table=10000
    -P gauss_mean=10000
    -P gauss_stddev=20000
    -P data_validation=false
    -P skip_write_errors=true
    data_dir/latte/scylladb_682.rn
