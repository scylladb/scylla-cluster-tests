# This is a test case for having 90% disk utilization with a lot of small tables.
# The data is split equally among 500 tables.
# The dataset size is aligned with 'i4i.xlarge' and RF = 3 = number-of-DB-nodes.
# It uses a c-s user-profile template for all 500 tables.
# It runs 4 batches of 125 tables each.
# On each batch cycle, 125 tables are created, then a load is generated for all of these tables.
# When all the 125 stress writes/reads are done, it continue with the next batch until stress to all 500 tables is completed (after 4 cycles).
# Each one of the 500 tables has both write and read load.

test_duration: 600

cs_user_profiles:
    - data_dir/templated-elasticity-tables.yaml

pre_create_schema: true
user_profile_table_count: 500
batch_size: 125
cs_duration: ''

n_loaders: 4
n_monitor_nodes: 1
n_db_nodes: 3
add_node_cnt: 0

instance_type_db: 'i4i.xlarge'
instance_type_loader: 'c6i.2xlarge'
user_prefix: 'longevity-elasticity-many-small-tables'
append_scylla_yaml:
  # NOTE: https://github.com/scylladb/scylla-monitoring/issues/2429
  enable_node_aggregated_table_metrics: false

cluster_health_check: false

nemesis_class_name: 'NoOpMonkey'
nemesis_interval: 60
